{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51bQlVgjmnWf"
   },
   "source": [
    "# **YoloV3(TensorFlow) 모델 실습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 사전 환경 세팅**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIUMAdGXm46J"
   },
   "source": [
    "### **1-1. TensorFlow 정상 설치 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create -n day14-1 python=3.9\n",
    "!conda activate day14-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install jupyter notebook\n",
    "!python -m ipykernel install --user --name day14-1 --display-name day14-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "oyrsdB9THu-8",
    "outputId": "a0b04911-7396-4807-af0d-04975315ac77"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxD-M-g4nZf_"
   },
   "source": [
    "### **1-2. Darknet weight 파일로 변환 처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xymK200gmV25",
    "outputId": "f7c19fab-4f8b-4d5c-eed3-5b70c148065e"
   },
   "outputs": [],
   "source": [
    "!python convert.py --weights ./data/yolov3.weights --output ./checkpoints/yolov3.tf\n",
    "!python convert.py --weights ./data/yolov3-tiny.weights --output ./checkpoints/yolov3-tiny.tf --tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySGg4Ols02rX"
   },
   "source": [
    "## **2. Detector 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tlgBiU4ZsZY5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from absl import app, logging, flags\n",
    "from absl.flags import FLAGS\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from yolov3_tf2.models import (\n",
    "    YoloV3, YoloV3Tiny\n",
    ")\n",
    "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
    "from yolov3_tf2.utils import draw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absl 라이브러리를 사용한 커맨드라인 플래그(옵션) 정의\n",
    "flags.DEFINE_string('classes', './data/coco.names', 'path to classes file')\n",
    "flags.DEFINE_string('weights', './checkpoints/yolov3.tf',\n",
    "                    'path to weights file')\n",
    "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
    "flags.DEFINE_integer('size', 416, 'resize images to')\n",
    "flags.DEFINE_string('image', './data/girl.png', 'path to input image')\n",
    "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
    "flags.DEFINE_string('output', './output.jpg', 'path to output image')\n",
    "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
    "\n",
    "# 앱 초기화 및 플래그 파싱\n",
    "app._run_init(['yolov3'], app.parse_flags_with_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 설정을 통해 사용 가능한 GPU 장치를 확인하고, GPU 메모리 활성화\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "laxApAGV07kw"
   },
   "source": [
    "## **3. pre-trained weight를 활용한 detection 테스트**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "colab_type": "code",
    "id": "2iKC1pvBnkDk",
    "outputId": "b15566f3-7c22-433e-c57b-d0e508d794cb"
   },
   "outputs": [],
   "source": [
    "# 테스트할 이미지 입력 경로 설정\n",
    "FLAGS.image = 'data/meme.jpg'\n",
    "\n",
    "# YOLOv3 기본 또는 tiny 모델 파이프라인 선택\n",
    "if FLAGS.tiny:\n",
    "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
    "else:\n",
    "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
    "      \n",
    "# 모델 weight 파일 로드\n",
    "yolo.load_weights(FLAGS.weights).expect_partial()\n",
    "logging.info('weights loaded')\n",
    "\n",
    "# 클래스 이름 로드\n",
    "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
    "logging.info('classes loaded')\n",
    "\n",
    "# 입력 이미지 로드\n",
    "img_raw = tf.image.decode_image(\n",
    "    open(FLAGS.image, 'rb').read(), channels=3)\n",
    "\n",
    "# 이미지 전처리\n",
    "img = tf.expand_dims(img_raw, 0) # 이미지 차원 확장 (배치 차원 추가)\n",
    "img = transform_images(img, FLAGS.size) # 이미지를 모델 입력 크기에 맞게 리사이즈 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측 수행\n",
    "t1 = time.time() # 시작 시간 기록\n",
    "boxes, scores, classes, nums = yolo(img) # 이미지에서 객체 탐지 수행\n",
    "t2 = time.time() # 종료 시간 기록\n",
    "logging.info('time: {}'.format(t2 - t1))\n",
    "\n",
    "# 탐지된 객체 정보 출력\n",
    "logging.info('detections:')\n",
    "for i in range(nums[0]):\n",
    "    logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\n",
    "                                        np.array(scores[0][i]),\n",
    "                                        np.array(boxes[0][i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 탐지 결과 이미지로 표시\n",
    "img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\n",
    "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
    "\n",
    "# Jupyter Notebook에서 이미지 표시\n",
    "from IPython.display import Image, display\n",
    "display(Image(data=bytes(cv2.imencode('.jpg', img)[1]), width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Up4Xcad81FSa"
   },
   "source": [
    "## **4. 신규 학습 진행**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-1. 데이터 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "-I8Ml-j4Iyuv",
    "outputId": "a1880906-4c01-4f08-a12b-ca2f37582a55"
   },
   "outputs": [],
   "source": [
    "# raw 데이터(tar) 압축 해제\n",
    "# !wget http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar -O ./data/voc2009_raw.tar\n",
    "!mkdir -p ./data/voc2009_raw\n",
    "!tar -xf ./data/voc2009_raw.tar -C ./data/voc2009_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "9lvttM39I5Na",
    "outputId": "faa0df6f-ab49-4476-b2e7-de3c4dbdb5d3"
   },
   "outputs": [],
   "source": [
    "# YOLOv3 학습을 위한 voc2012 학습 데이터 전처리 수행\n",
    "!python3 tools/voc2012.py \\\n",
    "  --data_dir './data/voc2009_raw/VOCdevkit/VOC2009' \\\n",
    "  --split train \\\n",
    "  --output_file ./data/voc_train.tfrecord\n",
    "\n",
    "# YOLOv3 학습을 위한 voc2012 검증 데이터 전처리 수행\n",
    "!python3 tools/voc2012.py \\\n",
    "  --data_dir './data/voc2009_raw/VOCdevkit/VOC2009' \\\n",
    "  --split val \\\n",
    "  --output_file ./data/voc_val.tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y -c nvidia cuda-nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "colab_type": "code",
    "id": "ZBhryo1I2dwG",
    "outputId": "79963b6f-7f30-4a3d-dd83-792ed28a790d"
   },
   "outputs": [],
   "source": [
    "# 학습 파라미터 설정 및 학습 시작\n",
    "!python3 train.py \\\n",
    "\t--dataset ./data/voc_train.tfrecord \\\n",
    "\t--val_dataset ./data/voc_val.tfrecord \\\n",
    "\t--classes ./data/voc2012.names \\\n",
    "\t--num_classes 20 \\\n",
    "\t--mode fit --transfer darknet \\\n",
    "\t--batch_size 8 \\\n",
    "\t--epochs 3 \\\n",
    "\t--weights ./checkpoints/yolov3.tf \\\n",
    "\t--weights_num_classes 80 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgtlCN1m1TKG"
   },
   "source": [
    "## **5. 신규 학습 weight를 활용한 추론**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "wok7x44vNYuP",
    "outputId": "45e152d6-041a-48c9-813d-9d1588d5b4b8"
   },
   "outputs": [],
   "source": [
    "FLAGS.num_classes = 20 # 모델이 인식할 클래스 수를 정의\n",
    "FLAGS.classes = 'data/voc2012.names'  # 클래스 이름이 정의된 파일 경로\n",
    "FLAGS.weights = 'checkpoints/yolov3_train_3.tf'  # 학습된 가중치 파일 경로\n",
    "FLAGS.image = 'data/meme.jpg'  # 추론에 사용할 입력 이미지 파일 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esTFKZzX7jYj"
   },
   "outputs": [],
   "source": [
    "# 3 epoch로 충분한 학습이 이루어지지 않아 낮은 threshold로 설정 및 추론 진행\n",
    "FLAGS.yolo_iou_threshold = 0.1  # 예측된 바운딩 박스 간의 IoU 임계값 설정\n",
    "FLAGS.yolo_score_threshold = 0.1  # 예측된 바운딩 박스의 점수 임계값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 YOLOv3 Tiny 또는 기본 YOLOv3로 설정\n",
    "if FLAGS.tiny:\n",
    "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)  # YOLOv3 Tiny 모델 초기화\n",
    "else:\n",
    "    yolo = YoloV3(classes=FLAGS.num_classes)  # YOLOv3 기본 모델 초기화\n",
    "\n",
    "# 학습된 가중치 로드\n",
    "yolo.load_weights(FLAGS.weights).expect_partial()\n",
    "logging.info('weights loaded')  # 가중치가 로드되었음을 로그에 기록\n",
    "\n",
    "# 클래스 이름을 로드\n",
    "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
    "logging.info('classes loaded')  # 클래스 이름이 로드되었음을 로그에 기록\n",
    "\n",
    "# 입력 이미지를 읽고 디코딩\n",
    "img_raw = tf.image.decode_image(\n",
    "    open(FLAGS.image, 'rb').read(), channels=3\n",
    ")\n",
    "\n",
    "# 배치 차원을 추가하여 모델에 맞게 확장\n",
    "img = tf.expand_dims(img_raw, 0)\n",
    "# 이미지를 모델 입력 크기로 변환 (예: 416x416)\n",
    "img = transform_images(img, FLAGS.size)\n",
    "\n",
    "t1 = time.time()  # 예측 시작 시간 기록\n",
    "# 이미지에 대해 예측 수행\n",
    "boxes, scores, classes, nums = yolo(img)\n",
    "t2 = time.time()  # 예측 종료 시간 기록\n",
    "logging.info('time: {}'.format(t2 - t1))  # 예측에 걸린 시간 로그에 기록\n",
    "\n",
    "logging.info('detections:')  # 탐지된 객체를 로그에 기록\n",
    "for i in range(nums[0]):\n",
    "    logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\n",
    "                                       np.array(scores[0][i]),\n",
    "                                       np.array(boxes[0][i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 색상 변환 (RGB에서 BGR로 변환하여 OpenCV에서 사용)\n",
    "img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\n",
    "# 예측된 바운딩 박스와 클래스 이름을 이미지에 그림\n",
    "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
    "# 결과 이미지를 파일로 저장\n",
    "cv2.imwrite(FLAGS.output, img)\n",
    "logging.info('output saved to: {}'.format(FLAGS.output))  # 결과 이미지 저장 로그\n",
    "\n",
    "# Jupyter Notebook에서 이미지를 표시\n",
    "from IPython.display import Image, display\n",
    "display(Image(data=bytes(cv2.imencode('.jpg', img)[1]), width=800))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "colab_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "object_detection_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
