{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51bQlVgjmnWf"
   },
   "source": [
    "# **YoloV5(PyTorch) 모델 실습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 사전 환경 세팅**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIUMAdGXm46J"
   },
   "source": [
    "### **1-1. PyTorch 정상 설치 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspace/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "oyrsdB9THu-8",
    "outputId": "a0b04911-7396-4807-af0d-04975315ac77"
   },
   "outputs": [],
   "source": [
    "!ls\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxD-M-g4nZf_"
   },
   "source": [
    "### **1-2. Pre-trained weight로 추론 진행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xymK200gmV25",
    "outputId": "f7c19fab-4f8b-4d5c-eed3-5b70c148065e"
   },
   "outputs": [],
   "source": [
    "# pretrained weight 인 yolov5l.pt 를 활용해 data/bus.jpg 이미지에 대해 추론 진행\n",
    "# !python detect.py --weights yolov5s.pt --source /workspace/yolov5/data/images/bus.jpg\n",
    "!python detect.py --weights yolov5s.pt --source /workspace/yolov5/data/images/zidane.jpg\n",
    "                                            #    img.jpg                         # image\n",
    "                                            #    vid.mp4                         # video\n",
    "                                            #    screen                          # screenshot\n",
    "                                            #    path/                           # directory\n",
    "                                            #    list.txt                        # list of images\n",
    "                                            #    list.streams                    # list of streams\n",
    "                                            #    'path/*.jpg'                    # glob\n",
    "                                            #    'https://youtu.be/LNwODJXcvt4'  # YouTube\n",
    "                                            #    'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 결과 시각화를 위한 모듈 로드\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# runs/detects/ 폴더 내 가장 최신 exp 확인\n",
    "exp_dirs = sorted(glob.glob('runs/detect/exp*'), key=os.path.getmtime)\n",
    "latest_exp_dir = exp_dirs[-1] if exp_dirs else None\n",
    "\n",
    "# 폴더 내 추론된 이미지가 있을 경우 출력\n",
    "if latest_exp_dir:\n",
    "    result_images = glob.glob(os.path.join(latest_exp_dir, '*.jpg'))\n",
    "    \n",
    "    if result_images:\n",
    "        display(Image(filename=result_images[0]))\n",
    "    else:\n",
    "        print(\"No result images found in the latest directory.\")\n",
    "else:\n",
    "    print(\"No 'exp*' directories found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. VOC 데이터셋 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# 함수: VOC 라벨을 YOLO 포맷으로 변환\n",
    "def convert_label(annotation_path, label_path, class_names):\n",
    "    def convert_box(size, box):\n",
    "        dw, dh = 1. / size[0], 1. / size[1]\n",
    "        x, y, w, h = (box[0] + box[1]) / 2.0 - 1, (box[2] + box[3]) / 2.0 - 1, box[1] - box[0], box[3] - box[2]\n",
    "        return x * dw, y * dh, w * dw, h * dh\n",
    "\n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    width, height = int(size.find('width').text), int(size.find('height').text)\n",
    "\n",
    "    with open(label_path, 'w') as out_file:\n",
    "        for obj in root.iter('object'):\n",
    "            cls = obj.find('name').text\n",
    "            if cls in class_names and int(obj.find('difficult').text) != 1:\n",
    "                xmlbox = obj.find('bndbox')\n",
    "                box = [float(xmlbox.find(x).text) for x in ('xmin', 'xmax', 'ymin', 'ymax')]\n",
    "                bbox = convert_box((width, height), box)\n",
    "                cls_id = class_names.index(cls)\n",
    "                out_file.write(f\"{cls_id} \" + \" \".join(map(str, bbox)) + '\\n')\n",
    "\n",
    "# 함수: URL에서 파일 다운로드\n",
    "def download_file(url, dest_path):\n",
    "    print(f\"Downloading {url}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    with open(dest_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(f\"Saved to {dest_path}\")\n",
    "\n",
    "# 함수: VOC 데이터셋 다운로드 및 준비\n",
    "def download_and_prepare_voc():\n",
    "    base_dir = Path('./datasets/VOC')\n",
    "    images_dir = base_dir / 'images'\n",
    "    labels_dir = base_dir / 'labels'\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Pascal VOC 데이터셋 다운로드 URL\n",
    "    voc_urls = {\n",
    "        'VOCtrainval_06-Nov-2007': 'https://github.com/ultralytics/assets/releases/download/v0.0.0/VOCtrainval_06-Nov-2007.zip',\n",
    "        'VOCtest_06-Nov-2007': 'https://github.com/ultralytics/assets/releases/download/v0.0.0/VOCtest_06-Nov-2007.zip',\n",
    "        'VOCtrainval_11-May-2012': 'https://github.com/ultralytics/assets/releases/download/v0.0.0/VOCtrainval_11-May-2012.zip'\n",
    "    }\n",
    "\n",
    "    # 데이터셋 다운로드 및 압축 해제\n",
    "    for name, url in voc_urls.items():\n",
    "        zip_path = base_dir / f\"{name}.zip\"\n",
    "        if not zip_path.exists():\n",
    "            download_file(url, zip_path)\n",
    "\n",
    "        # 압축 해제\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(images_dir)\n",
    "\n",
    "    # VOCdevkit 디렉토리 확인\n",
    "    voc_path = images_dir / 'VOCdevkit'\n",
    "    if not voc_path.exists():\n",
    "        raise FileNotFoundError(\"VOCdevkit directory not found after extraction.\")\n",
    "\n",
    "    # 클래스 목록\n",
    "    class_names = [\n",
    "        'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "        'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\n",
    "        'train', 'tvmonitor'\n",
    "    ]\n",
    "\n",
    "    # 데이터셋 변환\n",
    "    for year, image_set in [('2007', 'train'), ('2007', 'val'), ('2007', 'test'), ('2012', 'train'), ('2012', 'val')]:\n",
    "        image_set_file = voc_path / f'VOC{year}/ImageSets/Main/{image_set}.txt'\n",
    "        if not image_set_file.exists():\n",
    "            print(f\"Skipping {image_set} {year} - file not found: {image_set_file}\")\n",
    "            continue\n",
    "\n",
    "        with open(image_set_file, 'r') as f:\n",
    "            image_ids = f.read().strip().split()\n",
    "\n",
    "        for image_id in tqdm(image_ids, desc=f\"Processing {image_set} {year}\"):\n",
    "            annotation_path = voc_path / f'VOC{year}/Annotations/{image_id}.xml'\n",
    "            image_path = voc_path / f'VOC{year}/JPEGImages/{image_id}.jpg'\n",
    "            label_path = labels_dir / f\"{image_set}_{year}_{image_id}.txt\"\n",
    "\n",
    "            if annotation_path.exists() and image_path.exists():\n",
    "                # 이미지 복사 및 라벨 변환\n",
    "                convert_label(annotation_path, label_path, class_names)\n",
    "            else:\n",
    "                print(f\"Missing files for {image_id}: {annotation_path}, {image_path}\")\n",
    "\n",
    "# VOC 데이터셋 다운로드 및 준비 호출\n",
    "# 현재 단계에서는 불필요\n",
    "# download_and_prepare_voc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySGg4Ols02rX"
   },
   "source": [
    "## **3. Detector 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tlgBiU4ZsZY5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# YOLOv5 에 PYTHONPATH 지정\n",
    "FILE = Path(__file__).resolve() if \"__file__\" in globals() else Path.cwd()\n",
    "ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "\n",
    "from models.yolo import Model\n",
    "from utils.general import check_img_size, check_dataset, increment_path, colorstr\n",
    "from utils.torch_utils import select_device\n",
    "from utils.dataloaders import create_dataloader\n",
    "from utils.loss import ComputeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 파이프라인 정의\n",
    "def train(hyp, opt, device):\n",
    "    # 경로 설정\n",
    "    save_dir = Path(opt.save_dir)  # 결과 저장 디렉토리\n",
    "    epochs, batch_size, weights, data = opt.epochs, opt.batch_size, opt.weights, opt.data\n",
    "\n",
    "    # 데이터셋 및 모델 설정 로드\n",
    "    data_dict = check_dataset(data)  # data.yaml 파일 로드\n",
    "    train_path, val_path = data_dict['train'], data_dict['val']  # 학습 및 검증 데이터 경로\n",
    "    nc = int(data_dict['nc'])  # 클래스 수\n",
    "    names = data_dict['names']  # 클래스 이름\n",
    "\n",
    "    # 모델 생성\n",
    "    model = Model(opt.cfg, ch=3, nc=nc).to(device)  # 새로운 모델 생성\n",
    "    model.hyp = hyp  # 하이퍼파라미터 연결\n",
    "    imgsz = check_img_size(opt.imgsz, s=32)  # 이미지 크기 확인\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    train_loader, dataset = create_dataloader(train_path,  # 학습 데이터 경로\n",
    "                                              imgsz,  # 이미지 크기\n",
    "                                              batch_size,  # 배치 크기\n",
    "                                              32,  # 버퍼 크기\n",
    "                                              hyp=hyp,  # 하이퍼파라미터\n",
    "                                              augment=True,  # 데이터 증강 활성화\n",
    "                                              cache=None,  # 캐싱 비활성화\n",
    "                                              rect=False,  # 직사각형 모드 비활성화\n",
    "                                              rank=-1,  # 분산 학습 비활성화\n",
    "                                              workers=8,  # 워커 스레드 수\n",
    "                                              image_weights=False,  # 이미지 가중치 비활성화\n",
    "                                              prefix=colorstr('train: ')  # 로깅\n",
    "                                              )\n",
    "\n",
    "    # 옵티마이저 및 손실 함수 정의\n",
    "    optimizer = torch.optim.SGD(model.parameters(),  # 모델 매개변수\n",
    "                                 lr=hyp['lr0'],  # 초기 학습률\n",
    "                                 momentum=hyp['momentum'],  # 모멘텀\n",
    "                                 weight_decay=hyp['weight_decay'])  # 가중치 감소\n",
    "    compute_loss = ComputeLoss(model)  # 손실 함수 초기화\n",
    "\n",
    "    # 학습 루프\n",
    "    for epoch in range(epochs):  # 에포크 반복\n",
    "        model.train()  # 모델 학습 모드 설정\n",
    "        for imgs, targets, paths, _ in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}'):  # 배치 반복\n",
    "            imgs = imgs.to(device).float() / 255.0  # 이미지를 [0, 1]로 정규화\n",
    "            targets = targets.to(device)  # 타겟을 디바이스로 전송\n",
    "\n",
    "            # loss 계산\n",
    "            pred = model(imgs)  # 예측값 계산\n",
    "            loss, loss_items = compute_loss(pred, targets)  # 손실 계산\n",
    "\n",
    "            # 역방향 계산 및 최적화\n",
    "            optimizer.zero_grad()  # 그래디언트 초기화\n",
    "            loss.backward()  # 역방향 전파\n",
    "            optimizer.step()  # 매개변수 업데이트\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs} finished.')  # 에포크 완료 메시지 출력\n",
    "\n",
    "    # 모델 저장\n",
    "    torch.save(model.state_dict(), save_dir / 'last.pt')  # 모델 상태 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 정의\n",
    "hyp = {\n",
    "    'lr0': 0.01,  # 초기 학습률\n",
    "    'momentum': 0.937,  # 모멘텀\n",
    "    'weight_decay': 0.0005,  # 가중치 감소\n",
    "    'box': 0.05,  # 박스 손실 가중치\n",
    "    'cls': 0.5,  # 클래스 손실 가중치\n",
    "    'obj': 1.0,  # 객체 손실 가중치\n",
    "    'iou_t': 0.2,  # IoU 임계값\n",
    "    'anchor_t': 4.0,  # 앵커 임계값\n",
    "    'fl_gamma': 0.0,  # Focal Loss 감마값\n",
    "    'hsv_h': 0.015,  # HSV 색조 증강 범위\n",
    "    'hsv_s': 0.7,  # HSV 채도 증강 범위\n",
    "    'hsv_v': 0.4,  # HSV 명도 증강 범위\n",
    "    'degrees': 0.0,  # 회전 각도 증강 범위\n",
    "    'translate': 0.1,  # 이동 증강 범위\n",
    "    'scale': 0.5,  # 스케일 증강 범위\n",
    "    'shear': 0.0,  # 전단 증강 범위\n",
    "    'cls_pw': 1.0,  # 클래스 손실 가중치 파라미터\n",
    "    'obj_pw': 1.0,  # 객체 손실 가중치 파라미터\n",
    "    'mosaic': 1.0,  # 모자이크 증강 활성화 (기본값: 1.0)\n",
    "    'copy_paste': 0.0,  # Copy-Paste 증강 비활성화 (기본값: 0.0)\n",
    "    'perspective': 0.0,  # 원근법 증강 비활성화 (기본값: 0.0)\n",
    "    'mixup': 0.0,  # MixUp 증강 비활성화 (기본값: 0.0)\n",
    "    'flipud': 0.0,  # 세로 뒤집기 확률\n",
    "    'fliplr': 0.5,  # 가로 뒤집기 확률\n",
    "    # 필요한 경우 추가 증강 키를 여기에 추가...\n",
    "}\n",
    "\n",
    "# 옵션 정의\n",
    "class Options:\n",
    "    weights = ''  # 초기 가중치 경로\n",
    "    cfg = '/workspace/yolov5/models/yolov5l.yaml'  # 모델 설정 파일 경로\n",
    "    data = '/workspace/yolov5/data/VOC.yaml'  # 데이터셋 설정 파일 경로\n",
    "    epochs = 100  # 학습 에포크 수\n",
    "    batch_size = 8  # 모든 GPU의 총 배치 크기\n",
    "    imgsz = 640  # 학습 및 검증 이미지 크기 (픽셀 단위)\n",
    "    save_dir = 'runs/train'  # 결과 저장 디렉토리\n",
    "\n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # GPU 사용 가능 시 GPU 선택, 그렇지 않으면 CPU 사용\n",
    "    device = select_device('0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # 고유한 저장 디렉토리 생성\n",
    "    opt.save_dir = increment_path(Path(opt.save_dir) / 'exp')  # 저장 경로 증분\n",
    "    opt.save_dir.mkdir(parents=True, exist_ok=True)  # 디렉토리 생성\n",
    "    \n",
    "    # 학습 함수 실행\n",
    "    # train(hyp, opt, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgtlCN1m1TKG"
   },
   "source": [
    "## **4. 신규 학습 weight를 활용한 추론**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-1. 사전 학습된 모델 로드 및 추론**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-1. 학습된 가중치 불러오기\n",
    "# 이미 정의된 모델을 활용하여 가중치 로드\n",
    "data = opt.data\n",
    "data_dict = check_dataset(data)  # data.yaml 파일 로드\n",
    "nc = int(data_dict['nc'])  # 클래스 수\n",
    "model = Model(opt.cfg, ch=3, nc=nc).to(device)  # 새로운 모델 생성\n",
    "model.hyp = hyp  # 하이퍼파라미터 연결\n",
    "model.load_state_dict(torch.load(opt.save_dir / 'last.pt', map_location=device))  # 학습된 가중치 로드\n",
    "model.eval()  # 평가 모드 설정\n",
    "print(\"Trained weights loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-2. 이미지 로드 및 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-2. 이미지 로드 및 전처리\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), stride=32, auto=True, scale_fill=False, scale_up=True):\n",
    "    # 이미지 크기를 유지하면서 패딩 추가 (YOLO 입력 크기에 맞춤)\n",
    "    shape = img.shape[:2]  # 원본 이미지의 높이, 너비\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # 비율 계산\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scale_up:  # 작은 이미지는 확대하지 않음\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # 새 크기 계산\n",
    "    ratio = r, r  # 너비, 높이 비율\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # 패딩 추가\n",
    "    if auto:  # 32의 배수로 조정\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)\n",
    "    elif scale_fill:  # 크기를 정확히 채움\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = new_shape\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]\n",
    "\n",
    "    dw /= 2  # 패딩을 양쪽에 추가\n",
    "    dh /= 2\n",
    "\n",
    "    # 리사이즈 및 패딩\n",
    "    if shape[::-1] != new_unpad:  # 새 크기로 리사이즈\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # 패딩 추가\n",
    "\n",
    "    return img, ratio, (dw, dh)\n",
    "\n",
    "# 추론할 이미지 경로\n",
    "image_path = '/workspace/yolov5/data/images/bus.jpg'\n",
    "img_size = opt.imgsz  # 옵션에서 설정된 입력 이미지 크기\n",
    "\n",
    "# 이미지 로드 및 전처리\n",
    "img_raw = cv2.imread(image_path)  # OpenCV로 이미지 로드 (PIL 대신)\n",
    "img_raw = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)  # BGR -> RGB 변환\n",
    "img_transformed, _, _ = letterbox(img_raw, new_shape=img_size, auto=False)  # letterbox 적용\n",
    "img_tensor = transforms.ToTensor()(img_transformed).unsqueeze(0).to(device)  # 텐서로 변환 후 배치 차원 추가\n",
    "\n",
    "print(f\"Image preprocessed: {img_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-3. 추론 함수 및 결과 시각화 함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-3. 추론 함수 및 결과 시각화 함수 정의\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageDraw\n",
    "\n",
    "def run_inference(model, img_tensor):\n",
    "    with torch.no_grad():  # 그래디언트 비활성화\n",
    "        pred = model(img_tensor)  # 모델 추론\n",
    "        pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)  # NMS 적용\n",
    "    return pred\n",
    "\n",
    "def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):\n",
    "    # Rescale coordinates (xyxy) from img1_shape to img0_shape\n",
    "    if ratio_pad is None:  # Calculate from shapes\n",
    "        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new\n",
    "        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding\n",
    "    else:\n",
    "        gain = ratio_pad[0]\n",
    "        pad = ratio_pad[1]\n",
    "\n",
    "    coords[:, [0, 2]] -= pad[0]  # x padding\n",
    "    coords[:, [1, 3]] -= pad[1]  # y padding\n",
    "    coords[:, :4] /= gain\n",
    "    coords[:, :4] = coords[:, :4].clamp(min=0, max=img0_shape[1 if coords[:, 0].max() > 1 else 0])  # Clip bounding boxes\n",
    "    return coords\n",
    "\n",
    "def visualize_results(img_raw, pred, class_names, img_tensor_shape):\n",
    "    # OpenCV에서 로드된 이미지를 PIL 이미지로 변환\n",
    "    if isinstance(img_raw, np.ndarray):  # img_raw가 numpy.ndarray인지 확인\n",
    "        img_raw = Image.fromarray(img_raw)\n",
    "\n",
    "    draw = ImageDraw.Draw(img_raw)  # PIL 이미지 위에 그릴 도구 초기화\n",
    "    for det in pred:  # 각 객체에 대해 처리\n",
    "        if det is not None and len(det):\n",
    "            det[:, :4] = scale_coords(img_tensor_shape[2:], det[:, :4], img_raw.size).round()  # 좌표 스케일 조정\n",
    "            for *xyxy, conf, cls in det:\n",
    "                label = f\"{class_names[int(cls)]} {conf:.2f}\"  # 클래스 및 신뢰도\n",
    "                draw.rectangle(xyxy, outline=\"red\", width=2)  # 경계 상자 그리기\n",
    "                draw.text((xyxy[0], xyxy[1] - 10), label, fill=\"red\")  # 클래스 이름 및 신뢰도 텍스트 추가\n",
    "    return img_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-4. 결과 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-4. 결과 시각화\n",
    "class_names = [\n",
    "    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "    'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\n",
    "    'train', 'tvmonitor'\n",
    "]\n",
    "\n",
    "predictions = run_inference(model, img_tensor)  # 추론 실행\n",
    "result_img = visualize_results(img_raw, predictions, class_names, img_tensor.shape)  # 결과 시각화\n",
    "\n",
    "# 이미지 출력\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(result_img)\n",
    "plt.axis('off')\n",
    "result_img.show() "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "colab_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
