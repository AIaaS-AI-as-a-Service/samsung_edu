{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51bQlVgjmnWf"
   },
   "source": [
    "# **YoloV5(PyTorch) 모델 실습**\n",
    "- PyTorch 기반의 YoloV5 모델을 활용한 객체 탐지(Object Detection) 실습\n",
    "- VOC 데이터를 사용해 실습을 진행하며, 이미지에서 물체를 탐지하고 결과를 시각화 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 사전 환경 세팅**\n",
    "- 필요한 라이브러리 설치 및 불러오기\n",
    "- 모델 파일 및 관련 설정 파일 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIUMAdGXm46J"
   },
   "source": [
    "### **1-1. PyTorch 정상 설치 확인**\n",
    "- PyTorch는 딥러닝 모델을 구축 및 학습시키는 데 주로 사용되는 프레임워크\n",
    "- 설치 확인을 통해 실행 환경이 올바르게 설정되었는지 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 드라이브에서 datasets 관련 zip 파일 3가지를 받아서 yolov5/datasets/VOC 위치에 저장\n",
    "# S3 드라이브에서 checkpoints.zip 파일 받아서 yolov5/ 위치에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conda 환경 생성 및 활성화\n",
    "# 새로운 Conda 환경(day14-1)을 생성하고 Python 3.9 버전 설치\n",
    "\n",
    "# day14-1이라는 이름의 Conda 환경 생성\n",
    "# conda create -n day14-2 python=3.9\n",
    "\n",
    "# 생성한 day14-1 환경 활성화\n",
    "# conda activate day14-2\n",
    "\n",
    "# 필요한 패키지 설치 및 Jupyter Notebook 설정\n",
    "# requirements.txt 파일을 통해 필요한 패키지 설치\n",
    "# pip install -r requirements.txt\n",
    "\n",
    "# Jupyter Notebook 설치\n",
    "# pip install jupyter notebook\n",
    "\n",
    "# Jupyter Notebook에서 새로운 Conda 커널 설정\n",
    "# python -m ipykernel install --user --name day14-2 --display-name day14-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "oyrsdB9THu-8",
    "outputId": "a0b04911-7396-4807-af0d-04975315ac77"
   },
   "outputs": [],
   "source": [
    "# PyTorch 라이브러리 불러오기\n",
    "import torch\n",
    "\n",
    "# PyTorch 버전 확인\n",
    "print(torch.__version__) # PyTorch 버전 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxD-M-g4nZf_"
   },
   "source": [
    "### **1-2. Pre-trained weight로 추론 진행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xymK200gmV25",
    "outputId": "f7c19fab-4f8b-4d5c-eed3-5b70c148065e"
   },
   "outputs": [],
   "source": [
    "# pretrained weight 인 yolov5l.pt 를 활용해 data/bus.jpg 이미지에 대해 추론 진행\n",
    "# !python detect.py --weights yolov5s.pt --source /workspace/yolov5/data/images/bus.jpg\n",
    "!python detect.py --weights yolov5l.pt --source ./data/images/zidane.jpg\n",
    "                                            #    img.jpg                         # image\n",
    "                                            #    vid.mp4                         # video\n",
    "                                            #    screen                          # screenshot\n",
    "                                            #    path/                           # directory\n",
    "                                            #    list.txt                        # list of images\n",
    "                                            #    list.streams                    # list of streams\n",
    "                                            #    'path/*.jpg'                    # glob\n",
    "                                            #    'https://youtu.be/LNwODJXcvt4'  # YouTube\n",
    "                                            #    'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 필요한 모듈 로드\n",
    "# 이미지 시각화를 위해 IPython.display 모듈의 Image와 display 함수 사용\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 파일 검색과 디렉터리 작업을 위해 glob와 os 모듈 사용\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 2. 최신 추론 결과 디렉터리 탐색\n",
    "# runs/detect/ 경로 내 \"exp*\" 패턴에 맞는 디렉터리 검색\n",
    "exp_dirs = sorted(\n",
    "    glob.glob('runs/detect/exp*'),  # \"exp*\" 패턴에 맞는 디렉터리 검색\n",
    "    key=os.path.getmtime           # 마지막 수정 시간을 기준으로 정렬\n",
    ")\n",
    "# 최신 디렉터리 선택 (존재하지 않으면 None)\n",
    "latest_exp_dir = exp_dirs[-1] if exp_dirs else None\n",
    "\n",
    "# 3. 결과 이미지 확인 및 시각화\n",
    "if latest_exp_dir:  # 최신 디렉터리가 존재할 경우\n",
    "    # 최신 디렉터리 내 .jpg 이미지 파일 검색\n",
    "    result_images = glob.glob(os.path.join(latest_exp_dir, '*.jpg'))\n",
    "    \n",
    "    if result_images:  # 이미지 파일이 있을 경우\n",
    "        # 첫 번째 이미지 화면에 출력\n",
    "        display(Image(filename=result_images[0]))\n",
    "    else:  # 이미지 파일이 없을 경우\n",
    "        print(\"No result images found in the latest directory.\")\n",
    "else:  # \"exp*\" 디렉터리가 없을 경우\n",
    "    print(\"No 'exp*' directories found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. VOC 데이터셋 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 필요한 모듈 로드\n",
    "# os와 pathlib 모듈: 파일 및 디렉터리 작업을 쉽게 처리하기 위한 모듈\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# xml.etree.ElementTree: Pascal VOC 형식의 XML 파일을 처리하기 위한 모듈\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# tqdm: 작업 진행 상황을 표시하는 진행 바 제공\n",
    "from tqdm import tqdm\n",
    "\n",
    "# zipfile: ZIP 파일을 압축 해제하기 위한 모듈\n",
    "import zipfile\n",
    "\n",
    "\n",
    "# 2. 함수: VOC 라벨을 YOLO 포맷으로 변환\n",
    "def convert_label(annotation_path, label_path, class_names):\n",
    "    \"\"\"\n",
    "    Pascal VOC 형식의 라벨을 YOLO 포맷으로 변환하는 함수.\n",
    "    XML 형식의 annotation 파일을 읽어 YOLO 형식의 텍스트 파일로 변환.\n",
    "\n",
    "    Parameters:\n",
    "        annotation_path (str): VOC XML 파일 경로\n",
    "        label_path (str): YOLO 라벨 파일을 저장할 경로\n",
    "        class_names (list): Pascal VOC에서 사용할 클래스 이름 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    # VOC 형식의 바운딩 박스를 YOLO 포맷으로 변환하는 함수\n",
    "    def convert_box(size, box):\n",
    "        \"\"\"\n",
    "        VOC 형식의 바운딩 박스 좌표를 YOLO 포맷으로 변환.\n",
    "        바운딩 박스 중심 좌표와 너비, 높이를 이미지 크기에 대해 정규화.\n",
    "\n",
    "        Parameters:\n",
    "            size (tuple): (이미지 너비, 높이)\n",
    "            box (list): VOC 바운딩 박스 좌표 [xmin, xmax, ymin, ymax]\n",
    "\n",
    "        Returns:\n",
    "            tuple: YOLO 포맷 좌표 (x_center, y_center, width, height)\n",
    "        \"\"\"\n",
    "        dw, dh = 1. / size[0], 1. / size[1]  # 정규화 계수 계산\n",
    "        x, y, w, h = (box[0] + box[1]) / 2.0 - 1, (box[2] + box[3]) / 2.0 - 1, box[1] - box[0], box[3] - box[2]\n",
    "        return x * dw, y * dh, w * dw, h * dh\n",
    "\n",
    "    # XML 파일 파싱하여 root 요소 가져오기\n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # 이미지 크기 가져오기 (너비와 높이)\n",
    "    size = root.find('size')\n",
    "    width, height = int(size.find('width').text), int(size.find('height').text)\n",
    "\n",
    "    # YOLO 라벨 파일 생성\n",
    "    with open(label_path, 'w') as out_file:\n",
    "        for obj in root.iter('object'):  # 모든 객체 태그에 대해 반복\n",
    "            cls = obj.find('name').text  # 객체의 클래스 이름 가져오기\n",
    "            # 클래스 이름이 유효하고 \"difficult\" 속성이 1이 아니면 변환 수행\n",
    "            if cls in class_names and int(obj.find('difficult').text) != 1:\n",
    "                # 바운딩 박스 좌표 가져오기\n",
    "                xmlbox = obj.find('bndbox')\n",
    "                box = [float(xmlbox.find(x).text) for x in ('xmin', 'xmax', 'ymin', 'ymax')]\n",
    "                bbox = convert_box((width, height), box)  # YOLO 포맷으로 변환\n",
    "                cls_id = class_names.index(cls)  # 클래스 ID (인덱스) 가져오기\n",
    "                # YOLO 포맷으로 파일에 작성\n",
    "                out_file.write(f\"{cls_id} \" + \" \".join(map(str, bbox)) + '\\n')\n",
    "\n",
    "\n",
    "# 3. 함수: VOC 데이터셋 다운로드 및 준비\n",
    "def prepare_voc_dataset():\n",
    "    \"\"\"\n",
    "    로컬에 저장된 Pascal VOC 데이터셋 ZIP 파일을 사용하여 데이터를 준비.\n",
    "    데이터셋을 압축 해제하고 XML annotation 파일을 YOLO 포맷으로 변환.\n",
    "\n",
    "    Parameters:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # 데이터셋 경로 설정\n",
    "    base_dir = Path('./datasets/VOC')  # 데이터셋의 기본 디렉터리\n",
    "    images_dir = base_dir / 'images'  # 이미지가 저장될 디렉터리\n",
    "    labels_dir = base_dir / 'labels'  # YOLO 라벨 파일이 저장될 디렉터리\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)  # 디렉터리 생성 (이미 있으면 무시)\n",
    "    labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 로컬에 저장된 ZIP 파일 경로\n",
    "    zip_files = {\n",
    "        'VOCtrainval_06-Nov-2007': base_dir / 'VOCtrainval_06-Nov-2007.zip',\n",
    "        'VOCtest_06-Nov-2007': base_dir / 'VOCtest_06-Nov-2007.zip',\n",
    "        'VOCtrainval_11-May-2012': base_dir / 'VOCtrainval_11-May-2012.zip'\n",
    "    }\n",
    "\n",
    "    # 각 ZIP 파일 확인 및 처리\n",
    "    for name, zip_path in zip_files.items():\n",
    "        if not zip_path.exists():\n",
    "            print(f\"Error: ZIP file not found at {zip_path}. Please ensure the file is present.\")\n",
    "            continue  # ZIP 파일이 없으면 건너뛰기\n",
    "\n",
    "        # ZIP 파일 압축 해제\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(images_dir)  # 지정된 경로에 압축 해제\n",
    "\n",
    "    # VOC 데이터셋 디렉터리 확인\n",
    "    voc_path = images_dir / 'VOCdevkit'\n",
    "    if not voc_path.exists():\n",
    "        raise FileNotFoundError(\"VOCdevkit directory not found after extraction.\")\n",
    "\n",
    "    # Pascal VOC 클래스 이름 목록\n",
    "    class_names = [\n",
    "        'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "        'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\n",
    "        'train', 'tvmonitor'\n",
    "    ]\n",
    "\n",
    "    # 각 연도와 데이터셋 (train, val, test)에 대해 처리\n",
    "    for year, image_set in [('2007', 'train'), ('2007', 'val'), ('2007', 'test'), ('2012', 'train'), ('2012', 'val')]:\n",
    "        image_set_file = voc_path / f'VOC{year}/ImageSets/Main/{image_set}.txt'  # 이미지 ID가 저장된 텍스트 파일 경로\n",
    "        if not image_set_file.exists():\n",
    "            print(f\"Skipping {image_set} {year} - file not found: {image_set_file}\")\n",
    "            continue  # 파일이 없으면 건너뛰기\n",
    "\n",
    "        # 이미지 ID 목록 읽기\n",
    "        with open(image_set_file, 'r') as f:\n",
    "            image_ids = f.read().strip().split()\n",
    "\n",
    "        # 각 이미지 ID에 대해 라벨 변환 수행\n",
    "        for image_id in tqdm(image_ids, desc=f\"Processing {image_set} {year}\"):\n",
    "            annotation_path = voc_path / f'VOC{year}/Annotations/{image_id}.xml'  # XML annotation 파일 경로\n",
    "            image_path = voc_path / f'VOC{year}/JPEGImages/{image_id}.jpg'  # 이미지 파일 경로\n",
    "            label_path = labels_dir / f\"{image_set}_{year}_{image_id}.txt\"  # YOLO 라벨 파일 경로\n",
    "\n",
    "            # XML 파일과 이미지 파일이 모두 존재하는 경우 변환\n",
    "            if annotation_path.exists() and image_path.exists():\n",
    "                convert_label(annotation_path, label_path, class_names)\n",
    "            else:\n",
    "                print(f\"Missing files for {image_id}: {annotation_path}, {image_path}\")  # 누락된 파일 경고 메시지\n",
    "\n",
    "\n",
    "# 4. VOC 데이터셋 준비 함수 호출\n",
    "prepare_voc_dataset()  # 데이터셋 준비 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySGg4Ols02rX"
   },
   "source": [
    "## **3. Detector 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tlgBiU4ZsZY5"
   },
   "outputs": [],
   "source": [
    "# 1. 필요한 모듈 불러오기\n",
    "# os와 sys: 경로 설정 및 시스템 작업\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# pathlib: 파일 및 디렉터리 경로 작업을 위한 객체 기반 모듈\n",
    "from pathlib import Path\n",
    "\n",
    "# PyTorch 관련 라이브러리\n",
    "import torch\n",
    "\n",
    "# YAML 파일 읽기/쓰기\n",
    "import yaml\n",
    "\n",
    "# 명령줄 인자를 처리하는 argparse 모듈\n",
    "import argparse\n",
    "\n",
    "# NumPy: 고성능 수치 계산 라이브러리\n",
    "import numpy as np\n",
    "\n",
    "# tqdm: 작업 진행 상황 표시\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 2. YOLOv5 루트 디렉터리 경로 설정\n",
    "# 현재 파일의 경로를 기준으로 루트 디렉터리 찾기\n",
    "FILE = Path(__file__).resolve() if \"__file__\" in globals() else Path.cwd()\n",
    "ROOT = FILE.parents[0]  # YOLOv5의 루트 디렉터리\n",
    "\n",
    "# 루트 디렉터리가 PYTHONPATH에 없으면 추가\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# 3. YOLOv5 관련 모듈 불러오기\n",
    "# 모델 정의 및 학습 관련 기능 제공\n",
    "from models.yolo import Model\n",
    "\n",
    "# 일반 유틸리티: 이미지 크기, 데이터셋 확인, 경로 증가 등 기능\n",
    "from utils.general import check_img_size, check_dataset, increment_path, colorstr\n",
    "\n",
    "# PyTorch 관련 유틸리티: 장치 선택 등\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "# 데이터 로더: 데이터셋 생성 및 로드\n",
    "from utils.dataloaders import create_dataloader\n",
    "\n",
    "# 손실 계산 클래스\n",
    "from utils.loss import ComputeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모델 학습 파이프라인 정의\n",
    "def train(hyp, opt, device):\n",
    "    # 2. 경로 설정\n",
    "    # 결과를 저장할 디렉터리 경로 설정\n",
    "    save_dir = Path(opt.save_dir)\n",
    "    \n",
    "    # 학습 설정값 로드\n",
    "    epochs, batch_size, weights, data = opt.epochs, opt.batch_size, opt.weights, opt.data\n",
    "\n",
    "    # 3. 데이터셋 및 모델 설정 로드\n",
    "    # 데이터셋 정보 로드 (data.yaml 파일에서 경로와 설정 가져오기)\n",
    "    data_dict = check_dataset(data)\n",
    "    train_path, val_path = data_dict['train'], data_dict['val']  # 학습 및 검증 데이터 경로\n",
    "    nc = int(data_dict['nc'])  # 클래스 수\n",
    "    names = data_dict['names']  # 클래스 이름\n",
    "\n",
    "    # 모델 생성\n",
    "    model = Model(opt.cfg, ch=3, nc=nc).to(device)  # YOLO 모델 생성 (채널 수: 3, 클래스 수: nc)\n",
    "    model.hyp = hyp  # 하이퍼파라미터 연결\n",
    "    imgsz = check_img_size(opt.imgsz, s=32)  # 이미지 크기 확인 (32의 배수로 조정)\n",
    "\n",
    "    # 4. 데이터 로더 생성\n",
    "    # 학습 데이터 로드 및 데이터 증강 적용\n",
    "    train_loader, dataset = create_dataloader(\n",
    "        train_path,        # 학습 데이터 경로\n",
    "        imgsz,             # 입력 이미지 크기\n",
    "        batch_size,        # 배치 크기\n",
    "        8,                # 버퍼 크기\n",
    "        hyp=hyp,           # 하이퍼파라미터\n",
    "        augment=True,      # 데이터 증강 활성화\n",
    "        cache=None,        # 데이터 캐싱 비활성화\n",
    "        rect=False,        # 직사각형 크기 조정 비활성화\n",
    "        rank=-1,           # 분산 학습 비활성화\n",
    "        workers=8,         # 데이터 로드 워커 스레드 수\n",
    "        image_weights=False,  # 이미지 가중치 비활성화\n",
    "        prefix=colorstr('train: ')  # 로깅용 접두사\n",
    "    )\n",
    "\n",
    "    # 5. 옵티마이저 및 손실 함수 정의\n",
    "    # SGD 옵티마이저 생성 (기본 설정: 학습률, 모멘텀, 가중치 감소)\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),    # 모델 매개변수\n",
    "        lr=hyp['lr0'],         # 초기 학습률\n",
    "        momentum=hyp['momentum'],  # 모멘텀 설정\n",
    "        weight_decay=hyp['weight_decay']  # 가중치 감소\n",
    "    )\n",
    "    compute_loss = ComputeLoss(model)  # YOLO 손실 함수 초기화\n",
    "\n",
    "    # 6. 학습 루프\n",
    "    for epoch in range(epochs):  # 에포크 반복\n",
    "        model.train()  # 모델을 학습 모드로 설정\n",
    "        \n",
    "        # 배치 반복\n",
    "        for imgs, targets, paths, _ in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}'):\n",
    "            imgs = imgs.to(device).float() / 255.0  # 이미지 정규화 ([0, 255] → [0, 1])\n",
    "            targets = targets.to(device)  # 타겟 데이터 디바이스로 전송\n",
    "\n",
    "            # 손실 계산\n",
    "            pred = model(imgs)  # 모델 예측값 생성\n",
    "            loss, loss_items = compute_loss(pred, targets)  # 손실 및 개별 손실 항목 계산\n",
    "\n",
    "            # 역방향 전파 및 최적화\n",
    "            optimizer.zero_grad()  # 그래디언트 초기화\n",
    "            loss.backward()  # 역방향 전파 계산\n",
    "            optimizer.step()  # 매개변수 업데이트\n",
    "\n",
    "        # 에포크 완료 메시지\n",
    "        print(f'Epoch {epoch + 1}/{epochs} finished.')\n",
    "\n",
    "    # 7. 모델 저장\n",
    "    # 학습 완료 후 모델의 상태 저장 (마지막 상태 저장)\n",
    "    torch.save(model.state_dict(), save_dir / 'last.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 하이퍼파라미터 정의\n",
    "# 모델 학습에 필요한 주요 설정값 지정\n",
    "hyp = {\n",
    "    'lr0': 0.01,  # 초기 학습률\n",
    "    'momentum': 0.937,  # 모멘텀 (이전 업데이트를 반영하는 정도)\n",
    "    'weight_decay': 0.0005,  # 가중치 감소 (과적합 방지용 정규화)\n",
    "    'box': 0.05,  # 박스 손실 가중치 (정확한 박스 위치 예측)\n",
    "    'cls': 0.5,  # 클래스 손실 가중치 (정확한 클래스 예측)\n",
    "    'obj': 1.0,  # 객체 손실 가중치 (객체 유무 판별)\n",
    "    'iou_t': 0.2,  # IoU 임계값 (앵커와 객체의 최소 겹침 비율)\n",
    "    'anchor_t': 4.0,  # 앵커 임계값 (앵커 크기 조정 기준)\n",
    "    'fl_gamma': 0.0,  # Focal Loss 감마값 (Focal Loss 비활성화)\n",
    "    'hsv_h': 0.015,  # HSV 색조 증강 범위\n",
    "    'hsv_s': 0.7,  # HSV 채도 증강 범위\n",
    "    'hsv_v': 0.4,  # HSV 명도 증강 범위\n",
    "    'degrees': 0.0,  # 회전 증강 각도 (기본값: 0도)\n",
    "    'translate': 0.1,  # 이동 증강 범위 (이미지 이동 비율)\n",
    "    'scale': 0.5,  # 스케일 증강 범위 (이미지 확대/축소 비율)\n",
    "    'shear': 0.0,  # 전단 증강 비율 (기울기 조정)\n",
    "    'cls_pw': 1.0,  # 클래스 손실 가중치 파라미터\n",
    "    'obj_pw': 1.0,  # 객체 손실 가중치 파라미터\n",
    "    'mosaic': 1.0,  # 모자이크 증강 활성화 (다양한 이미지 혼합)\n",
    "    'copy_paste': 0.0,  # Copy-Paste 증강 비활성화\n",
    "    'perspective': 0.0,  # 원근법 증강 비활성화\n",
    "    'mixup': 0.0,  # MixUp 증강 비활성화\n",
    "    'flipud': 0.0,  # 세로 뒤집기 확률 (기본값: 0%)\n",
    "    'fliplr': 0.5,  # 가로 뒤집기 확률 (기본값: 50%)\n",
    "}\n",
    "\n",
    "# 2. 옵션 정의\n",
    "# 학습 설정값과 경로를 포함한 클래스 생성\n",
    "class Options:\n",
    "    weights = ''  # 초기 가중치 경로 (사전 학습 모델 사용 시 지정)\n",
    "    cfg = './models/yolov5l.yaml'  # 모델 설정 파일 경로\n",
    "    data = './data/VOC.yaml'  # 데이터셋 설정 파일 경로\n",
    "    epochs = 100  # 학습 반복 횟수 (에포크 수)\n",
    "    batch_size = 8  # 배치 크기 (모든 GPU의 총 합)\n",
    "    imgsz = 640  # 이미지 크기 (학습 및 검증에 사용되는 입력 크기)\n",
    "    save_dir = 'runs/train'  # 결과 저장 디렉터리\n",
    "\n",
    "# 옵션 객체 생성\n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 1. 학습에 사용할 디바이스 선택\n",
    "    # GPU가 사용 가능한 경우 '0'번 GPU 선택, 그렇지 않으면 CPU 사용\n",
    "    device = select_device('0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # 2. 고유한 저장 디렉토리 생성\n",
    "    # 'runs/train/exp' 형식으로 저장 경로를 생성하고 기존 경로와 중복되지 않도록 증분\n",
    "    opt.save_dir = increment_path(Path(opt.save_dir) / 'exp')  # 저장 경로 설정\n",
    "    opt.save_dir.mkdir(parents=True, exist_ok=True)  # 디렉토리 생성 (상위 디렉토리 포함)\n",
    "\n",
    "    # 3. 학습 함수 실행\n",
    "    train(hyp, opt, device)  # 실제 학습을 시작하려면 주석을 해제하여 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgtlCN1m1TKG"
   },
   "source": [
    "## **4. 신규 학습 weight를 활용한 추론**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-1. 사전 학습된 모델 로드 및 추론**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-1. 학습된 가중치 불러오기\n",
    "# 1. 데이터셋 정보 로드\n",
    "# 데이터셋 설정 파일 로드 (data.yaml)\n",
    "data = opt.data\n",
    "data_dict = check_dataset(data)  # 데이터셋 정보 로드\n",
    "nc = int(data_dict['nc'])  # 클래스 수 가져오기\n",
    "\n",
    "# 2. 모델 생성\n",
    "# YOLO 모델 초기화 (채널: 3, 클래스 수: nc)\n",
    "model = Model(opt.cfg, ch=3, nc=nc).to(device)\n",
    "\n",
    "# 3. 하이퍼파라미터 연결\n",
    "# 학습에 사용했던 하이퍼파라미터 적용\n",
    "model.hyp = hyp\n",
    "\n",
    "# 4. 학습된 가중치 불러오기\n",
    "# 저장된 가중치 파일('last.pt')을 디바이스에 맞게 로드\n",
    "model.load_state_dict(torch.load(opt.save_dir / 'last.pt', map_location=device))\n",
    "\n",
    "# 5. 모델 평가 모드 설정\n",
    "# 학습 과정이 아닌 평가 과정에 적합한 설정으로 전환\n",
    "model.eval()\n",
    "\n",
    "# 6. 완료 메시지 출력\n",
    "print(\"Trained weights loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-2. 이미지 로드 및 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-2. 이미지 로드 및 전처리\n",
    "from PIL import Image  # 이미지 처리를 위한 라이브러리\n",
    "from torchvision.transforms import transforms  # PyTorch 변환 유틸리티\n",
    "import cv2  # 이미지 처리 라이브러리 (OpenCV)\n",
    "import numpy as np  # 수치 계산 라이브러리 (NumPy)\n",
    "\n",
    "# 함수: letterbox\n",
    "# 이미지 크기를 유지하면서 YOLO 모델의 입력 크기에 맞게 패딩 추가\n",
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), stride=32, auto=True, scale_fill=False, scale_up=True):\n",
    "    # 원본 이미지 크기 (높이, 너비)\n",
    "    shape = img.shape[:2]\n",
    "    if isinstance(new_shape, int):  # 새로운 크기를 튜플 형태로 변환\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # 이미지 크기 조정 비율 계산\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  # 높이와 너비 비율 중 최소값 선택\n",
    "    if not scale_up:  # 작은 이미지를 확대하지 않도록 제한\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # 리사이즈된 크기 계산\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))  # 새로운 크기\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # 추가 패딩 계산\n",
    "    if auto:  # 32의 배수로 맞추기\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)\n",
    "    elif scale_fill:  # 정확히 새 크기로 채우기\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = new_shape\n",
    "        r = new_shape[1] / shape[1], new_shape[0] / shape[0]\n",
    "\n",
    "    # 패딩을 양쪽에 동일하게 분배\n",
    "    dw /= 2\n",
    "    dh /= 2\n",
    "\n",
    "    # 이미지를 새로운 크기로 리사이즈\n",
    "    if shape[::-1] != new_unpad:\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    # 패딩 추가\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return img, r, (dw, dh)\n",
    "\n",
    "# 이미지 경로 설정\n",
    "image_path = '/workspace/yolov5/data/images/bus.jpg'  # 추론할 이미지 경로\n",
    "img_size = opt.imgsz  # 입력 이미지 크기 (옵션에서 설정)\n",
    "\n",
    "# 1. 이미지 로드\n",
    "img_raw = cv2.imread(image_path)  # OpenCV를 사용하여 이미지 로드\n",
    "img_raw = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)  # OpenCV의 BGR 포맷을 RGB로 변환\n",
    "\n",
    "# 2. 이미지 전처리\n",
    "# YOLO 모델에 적합한 입력 크기로 letterbox 함수 적용\n",
    "img_transformed, _, _ = letterbox(img_raw, new_shape=img_size, auto=False)\n",
    "\n",
    "# 3. 텐서 변환\n",
    "# PyTorch 텐서로 변환 (이미지 → [0, 1] 범위로 정규화, 배치 차원 추가)\n",
    "img_tensor = transforms.ToTensor()(img_transformed).unsqueeze(0).to(device)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Image preprocessed: {img_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-3. 추론 함수 및 결과 시각화 함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-3. 추론 함수 및 결과 시각화 함수 정의\n",
    "import matplotlib.pyplot as plt  # 결과 시각화를 위한 라이브러리\n",
    "from PIL import Image, ImageDraw  # 이미지를 처리하고 주석 추가\n",
    "import torch  # PyTorch\n",
    "import numpy as np  # 수치 계산\n",
    "\n",
    "# 1. 추론 함수 정의\n",
    "def run_inference(model, img_tensor):\n",
    "    with torch.no_grad():  # 추론 시 그래디언트 비활성화로 메모리 절약\n",
    "        pred = model(img_tensor)  # 모델에 입력 텐서를 전달하여 예측값 계산\n",
    "        # 비최대 억제(NMS)를 통해 겹치는 박스 제거\n",
    "        pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)\n",
    "    return pred\n",
    "\n",
    "# 2. 좌표 스케일 변환 함수 정의\n",
    "def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):\n",
    "    # 모델 입력 이미지 크기(img1_shape) 기준 좌표를 원본 이미지 크기(img0_shape) 기준으로 변환\n",
    "    if ratio_pad is None:  # 스케일 비율과 패딩 계산\n",
    "        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # 비율 계산\n",
    "        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # 패딩 계산\n",
    "    else:\n",
    "        gain = ratio_pad[0]\n",
    "        pad = ratio_pad[1]\n",
    "\n",
    "    # 좌표 변환: 패딩 제거 및 스케일 적용\n",
    "    coords[:, [0, 2]] -= pad[0]  # x 좌표\n",
    "    coords[:, [1, 3]] -= pad[1]  # y 좌표\n",
    "    coords[:, :4] /= gain\n",
    "    # 좌표를 이미지 크기에 맞게 클리핑\n",
    "    coords[:, :4] = coords[:, :4].clamp(min=0, max=img0_shape[1 if coords[:, 0].max() > 1 else 0])\n",
    "    return coords\n",
    "\n",
    "# 3. 결과 시각화 함수 정의\n",
    "def visualize_results(img_raw, pred, class_names, img_tensor_shape):\n",
    "    # OpenCV로 로드된 이미지(numpy.ndarray)를 PIL 이미지로 변환\n",
    "    if isinstance(img_raw, np.ndarray):\n",
    "        img_raw = Image.fromarray(img_raw)\n",
    "\n",
    "    # PIL 이미지에 그리기 도구 초기화\n",
    "    draw = ImageDraw.Draw(img_raw)\n",
    "    for det in pred:  # 각 객체에 대해 처리\n",
    "        if det is not None and len(det):  # 검출된 객체가 있는 경우만 처리\n",
    "            # 모델 좌표를 원본 이미지 좌표로 변환\n",
    "            det[:, :4] = scale_coords(img_tensor_shape[2:], det[:, :4], img_raw.size).round()\n",
    "            for *xyxy, conf, cls in det:\n",
    "                # 클래스 이름과 신뢰도 준비\n",
    "                label = f\"{class_names[int(cls)]} {conf:.2f}\"\n",
    "                # 경계 상자 그리기\n",
    "                draw.rectangle(xyxy, outline=\"red\", width=2)\n",
    "                # 경계 상자 위에 클래스 이름 및 신뢰도 추가\n",
    "                draw.text((xyxy[0], xyxy[1] - 10), label, fill=\"red\")\n",
    "    return img_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-4. 결과 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-4. 결과 시각화\n",
    "\n",
    "# 1. 클래스 이름 정의\n",
    "# VOC 데이터셋에 포함된 클래스 목록\n",
    "class_names = [\n",
    "    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "    'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\n",
    "    'train', 'tvmonitor'\n",
    "]\n",
    "\n",
    "# 2. 모델 추론 실행\n",
    "# 이미 전처리된 텐서를 입력으로 받아 객체 검출 수행\n",
    "predictions = run_inference(model, img_tensor)\n",
    "\n",
    "# 3. 결과 시각화\n",
    "# 원본 이미지와 추론 결과를 바탕으로 시각화된 이미지 생성\n",
    "result_img = visualize_results(img_raw, predictions, class_names, img_tensor.shape)\n",
    "\n",
    "# 4. 시각화된 이미지 출력\n",
    "# Matplotlib을 사용하여 결과 이미지 출력\n",
    "plt.figure(figsize=(10, 10))  # 출력 크기 설정\n",
    "plt.imshow(result_img)  # 이미지 표시\n",
    "plt.axis('off')  # 축 제거\n",
    "result_img.show()  # PIL의 기본 이미지 뷰어로 열기"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "colab_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "day14-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
