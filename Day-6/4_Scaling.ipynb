{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **📊 데이터 스케일링(Scaling)**\n",
    "- 정의\n",
    "    - 데이터를 의도한 컨텍스트에 맞춰 변환하는 작업\n",
    "- 표준화(Standardization): 데이터가 평균으로부터 얼마나 떨어져 분포하는지 표현하는 변환\n",
    "- 정규화(Normalization): 데이터의 상대적 크기에 대한 영향을 줄이기 위한 변환\n",
    "- 그 외에도 의도에 따라 *로그(log) 변환*, *제곱근(square root) 변환*, *Box-cox 변환*, *Power 변환* 등을 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 데이터 불러오기 및 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 사용할 열의 데이터만 일부 추출\n",
    "data = pd.read_csv('./data/titanic.csv', usecols=['Pclass', 'Age', 'Fare', 'Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1-1 결측치 처리**\n",
    "- Age 데이터에 대한 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치가 존재하는 데이터에 대한 확인\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Age]의 중앙값을 활용한 결측치 처리\n",
    "data['Age'] = data['Age'].fillna(data['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1-2 범주형 데이터에 대한 변환**\n",
    "- ordinal number encoding에 따라 숫자형 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PclassDict = {\"First\":1, \"Second\":2, \"Third\": 3,}\n",
    "\n",
    "# [Ordinal_Pclass] 라는 새로운 열에 기존의 Pclass의 데이터를 PclassDict로 매핑\n",
    "data['Pclass'] = data[\"Pclass\"].map(PclassDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 표준화(Standardization)**\n",
    "\n",
    "- 데이터의 특성을 공통된 스케일로 변환하여 모델이 각 변수의 중요도를 공정하게 다루도록 조정\n",
    "\n",
    "\\begin{equation}\n",
    "{z} = (x-\\mu) / \\sigma  \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    " + $z$: 표준화된 값\n",
    " + $x$: 원본 데이터 값\n",
    " + $\\mu$: 데이터의 평균값\n",
    " + $\\sigma$: 데이터의 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화 적용을 위한 라이브러리 불러오기\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 표준화를 취하기 위한 인스턴스 생성\n",
    "standard = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_std = standard.fit_transform(data)\n",
    "\n",
    "# 결과 확인\n",
    "data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 형태로 변환하여 데이터 확인\n",
    "pd.DataFrame(data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화를 위한 모듈 불러오기\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터의 표준화는 각 열(Column)을 기준으로 동작을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터의 [Pclass]에 대한 분포 확인\n",
    "plt.hist(data['Pclass'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화 처리된 [Pclass]에 대한 분포 확인\n",
    "# scaled 데이터에 대해서 두번째 열([Pclass])의 모든 데이터를 선택\n",
    "plt.hist(data_scaled[:, 1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터의 [Pclass]에 대한 분포 확인\n",
    "plt.hist(data['Age'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화 처리된 [Age]에 대한 분포 확인\n",
    "# scaled 데이터에 대해서 세번째 열([Age])의 모든 데이터를 선택\n",
    "plt.hist(data_scaled[:, 2], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터의 [Fare]에 대한 분포 확인\n",
    "plt.hist(data['Fare'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화 처리된 [Fare]에 대한 분포 확인\n",
    "# scaled 데이터에 대해서 두번째 열([Fare])의 모든 데이터를 선택\n",
    "plt.hist(data_scaled[:, 3], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 정규화(Normalization)**\n",
    "\n",
    "- 데이터의 크기나 범위를 조정하여 일정한 범위로 맞추는 방법\n",
    "- 모델의 학습 과정에서 특정 feature이 과도한 영향을 미치지 않도록 하거나, 알고리즘의 수렴 속도를 높이는 데 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3-1 Min-Max Scaling**\n",
    "\n",
    "- 데이터의 최소값, 최대값을 사용하여 데이터를 0과 1 사이의 값으로 변환\n",
    "\n",
    "\\begin{equation}\n",
    "{X'} = X - X_{min} / X_{max} - X_{min} \\tag {2}\n",
    "\\end{equation}\n",
    "\n",
    " + $X$: 원본 데이터\n",
    " + $X_{min}$: 원본 데이터의 최솟값\n",
    " + $X_{max}$: 원본 데이터의 최댓값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaling을 수행하기 위한 모듈 불러오기\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaling을 진행하기 위한 인스턴스 생성\n",
    "min_max = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max scaling을 진행한 데이터를 활용해 새로운 데이터프레임 생성\n",
    "data_min_max = pd.DataFrame(min_max.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "data_min_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 히스토그램을 통한 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Pclass] 열에 대한 데이터 분포 확인\n",
    "plt.hist(data['Pclass'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_min_max['Pclass'], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3-2 Robust Scaler**\n",
    "\n",
    "- 데이터의 중앙값(median)과 사분위수 범위(IQR, interquartile range)를 사용하여 데이터를 스케일링\n",
    "- 데이터의 분포가 비정상적이거나 이상치가 많은 경우에 사용\n",
    "\n",
    "\\begin{equation}\n",
    "{X'} = X - median(X) / IQR(X) \\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    " + $X$: 원본 데이터\n",
    " + $median(X)$: 원본 데이터의 중앙값\n",
    " + $IQR(X)$: 원본 데이터의 사분위수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust scaling을 수행할 모듈 불러오기\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# 스케일링을 수행할 인스턴스 생성\n",
    "robust = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각각의 column에 대해서 scaling을 진행한 결과를 새로운 데이터프레임에 저장\n",
    "data_robust_scale = pd.DataFrame(robust.fit_transform(data), columns= data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "data_robust_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 히스토그램을 통한 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Pclass] 열에 대한 데이터 분포 확인\n",
    "plt.hist(data['Pclass'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_robust_scale['Pclass'], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3-3 MaxAbs Scaler**\n",
    "\n",
    "- 데이터의 중앙값(median)과 사분위수 범위(IQR, interquartile range)를 사용하여 데이터를 스케일링\n",
    "- 데이터의 분포가 비정상적이거나 이상치가 많은 경우에 사용\n",
    "\n",
    "\\begin{equation}\n",
    "{X'} = X / max(|X|) \\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    " + $X$: 원본 데이터\n",
    " + $|X|$: 데이터의 절댓값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxAbs scaling을 수행할 모듈 불러오기\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# 스케일링을 수행할 인스턴스 생성\n",
    "maxabs = MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각각의 column에 대해서 scaling을 진행한 결과를 새로운 데이터프레임에 저장\n",
    "data_maxabs_scale = pd.DataFrame(maxabs.fit_transform(data), columns= data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "data_maxabs_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 히스토그램을 통한 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Pclass] 열에 대한 데이터 분포 확인\n",
    "plt.hist(data['Pclass'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_maxabs_scale['Pclass'], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Gaussian Transformation**\n",
    "\n",
    "- 데이터의 분포를 정규 분포에 가깝게 만들어 통계 분석에 용이하도록 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속형 데이터에 대해 처리하기 위해 [Pclass] 열 데이터 제거\n",
    "data.drop('Pclass', inplace=True, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변환 및 시각화를 위한 모듈 불러오기\n",
    "import scipy.stats as stat\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 시각화를 위한 함수 정의\n",
    "def plot_data(dataframe, column):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # 두 개의 그래프 중 첫번째 그래프\n",
    "    plt.subplot(1, 2, 1)\n",
    "    dataframe[column].hist()\n",
    "\n",
    "    # 두 개의 그래프 중 두번째 그래프\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    # column의 데이터가 정규분포를 따르는지 확인하기 위한 플롯을 생성\n",
    "    # dist='norm': 데이터가 정규분포를 따르는지 여부를 검증\n",
    "    # plot=pylab: 플롯을 그릴 객체를 pylab으로 지정\n",
    "    stat.probplot(dataframe[column], dist='norm', plot=pylab)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-1 Log transformation**\n",
    "- 데이터의 값이 너무 크거나 분포가 긴 꼬리(long tail)를 갖는 경우에 사용됨\n",
    "- 데이터에 대해 log(X), log(X+1) 등의 변환을 적용하여 스케일링을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Age] 데이터의 확인\n",
    "plot_data(data, 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그래프 상 plot의 포인트가 붉은 선을 따라 그려질 경우 정규 분포에 따르고 있다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 열을 추가해 Age 데이터에 대해서 로그 변환을 수행\n",
    "data['Age_Log'] = np.log(data['Age'])\n",
    "\n",
    "# 로그 변환을 수행한 데이터에 대해 시각화\n",
    "plot_data(data, 'Age_Log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-2 Square Root transformation**\n",
    "- 데이터의 값이 너무 크거나, 분포의 비대칭성을 줄이기 위해 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Age] 데이터의 분포 확인\n",
    "plot_data(data, 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제곱근 변환을 수행한 데이터를 데이터프레임 새로운 열에 저장\n",
    "data['Age_squared'] = data['Age']**(1/2)\n",
    "\n",
    "# 제곱근 변환을 수행한 결과에 대한 시각화\n",
    "plot_data(data, 'Age_squared')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4-3 Box-Cox transformation**\n",
    "- 데이터가 정규 분포에 더 가깝도록 조정하기 위해 사용됨\n",
    "- 파라미터를 조정하여 다양한 형태의 변환을 수행할 수 있음\n",
    "\n",
    "$$X'=\n",
    "\\begin{cases}\n",
    " X^{\\lambda} - 1 / \\lambda, \\; if\\ \\lambda \\neq 0 \\\\ \\tag{3}\n",
    " log(X), \\; if\\ \\lambda = 0\n",
    "\\end{cases}$$\n",
    " \n",
    " + $X$: 원본 데이터\n",
    " + $\\lambda$: 최적의 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Age] 데이터의 분포 확인\n",
    "plot_data(data, 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Age] 열의 데이터에 대한 box-cox 변환 수행\n",
    "# 이때 변환에서 사용된 최적의 파라미터를 반환\n",
    "data['Age_boxcox'], parameters = stat.boxcox(data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box-cox 변환에서 사용된 최적의 파라미터 확인\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box-cox 변환이 수행된 데이터의 분포 확인\n",
    "plot_data(data, 'Age_boxcox')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "day6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
