{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **문제 1. 과적합(Overfitting)을 방지하기 위한 방법으로 적절하지 않은 것은 무엇인가요?**\n",
    "1. 데이터 증강(Data Augmentation)\n",
    "2. Early Stopping 사용\n",
    "3. 모델의 복잡도 증가\n",
    "4. Dropout 레이어 추가\n",
    "5. L2 Regularization 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **문제 2.문제 다음 중 Gradient Descent(최적화 알고리즘) 중에서 학습률을 각 파라미터에 맞게 자동으로 조정하는 알고리즘은 무엇인가요?**\n",
    "1. SGD (Stochastic Gradient Descent)\n",
    "2. Momentum\n",
    "3. RMSProp\n",
    "4. Dropout\n",
    "5. Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **문제 3.과적합 방지와 직접적으로 관련이 없는 최적화 방법은 무엇인가요?**\n",
    "1. L2 Regularization\n",
    "2. Dropout\n",
    "3. Data Augmentation\n",
    "4. RMSProp\n",
    "5. Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **문제 4. Adam Optimizer가 기존 SGD에 비해 더 효과적으로 동작하는 이유로 적절하지 않은 설명은 무엇인가요?**\n",
    "1. 학습률을 자동으로 조정한다.\n",
    "2. 과적합을 방지하기 위해 정규화를 적용한다.\n",
    "3. 일차(momentum)와 이차(second moment) 통계 정보를 모두 활용한다.\n",
    "4. 비정상적인 데이터 분포에서도 안정적으로 학습한다.\n",
    "5. SGD보다 빠르게 최적점을 탐색한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Contents/saddle_point.png\" alt=\"Saddle Point\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **문제 5. Saddle Point는 기울기(Gradient)가 0이지만, 최소값도 최대값도 아닌 지점으로, 최적화 알고리즘의 수렴을 방해할 수 있는 점을 의미합니다. <br> 최적화 문제에서 Saddle Point에 대한 해결 방안으로 적절하지 않은 것은 무엇인가요?**\n",
    "1. 학습률을 동적으로 조정하는 RMSProp 사용한다.\n",
    "2. 가중치 초기화를 다양하게 설정하여 학습 시작점 변경한다.\n",
    "3. 모멘텀 기반 최적화 알고리즘 사용한다.\n",
    "4. 손실 함수의 평균값을 사용하는 데이터 정규화한다.\n",
    "5. 적응형 학습률 알고리즘 사용한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
