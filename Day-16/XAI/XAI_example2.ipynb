{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Grad CAM(Gradient Class Activation Map)**\n",
    "* CAM(Class Activation Map): CNN의 특정 클래스에 대한 활성화 지도를 시각화하는 기법으로, 해당 클래스와 연관된 이미지 영역을 강조하여 모델이 어떤 부분에 주목\n",
    "* Grad-CAM (Gradient-weighted Class Activation Map): 마지막 convolution layer의 특성과 해당 클래스의 그래디언트를 결합해 클래스별로 중요한 이미지 영역을 시각\n",
    "* 과정 \n",
    "    1. Forward Propagation: 이미지를 모델에 입력하여, 마지막 convolution layer의 feature map과 출력 예측값(softmax 결과) \n",
    "    2. Backpropagation: 관심 있는 클래스에 대해 예측값의 그래디언트를 계산하여, 마지막 convolution layer의 각 채널(feature map)에 대한 기여도 계산\n",
    "    3. Weight 계산: 각 채널의 중요도를 나타내는 가중치(α_k)를 그래디언트를 평균내어 계산\n",
    "    4. Weighted Combination: 가중치와 feature map을 결합하여 클래스에 대한 활성화 맵을 계산\n",
    "    5. Upsampling: 활성화 맵을 입력 이미지 크기로 보간(upsampling)하여 관심 있는 영역을 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Contents_XAI/Grad-CAM.png\" alt=\"Grad-CAM\" width=\"800\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 08:04:40.089710: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-16 08:04:40.116272: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-16 08:04:40.510642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import resnet50,ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 신경망 모델을 불러오고 신경망 구조를 확인\n",
    "#model=ResNet50(weights='imagenet')\n",
    "model = ResNet50(weights=None)\n",
    "model.load_weights('./resnet50_weights.h5') \n",
    "model.summary()\n",
    "\n",
    "# 지정된 영상을 불러와 크기 조정하고 화면에 디스플레이\n",
    "image_path='./hummingbird.jpg'\n",
    "img=image.load_img(image_path,target_size=(224,224))\n",
    "plt.matshow(img)\n",
    "\n",
    "# 영상을 신경망 입력 형태로 변환\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "x=resnet50.preprocess_input(x)\n",
    "\n",
    "# 인식을 시도하고 top-5 결과를 출력\n",
    "preds=model.predict(x)\n",
    "print(\"예측 결과:\", resnet50.decode_predictions(preds,top=5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델의 특징 추출(컨볼루션층) 부분에서 마지막 층을 지정\n",
    "# 특징 추출 부분만으로 구성된 모델 model_1 만들기\n",
    "last_conv_layer=model.get_layer(\"conv5_block3_out\")\n",
    "\n",
    "model_1=keras.Model(model.inputs,last_conv_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류(전역평균 풀링 또는 완전연결층) 부분만으로 구성된 모델 model_2 만들기\n",
    "input_2=keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "x_2=model.get_layer(\"avg_pool\")(input_2)\n",
    "x_2=model.get_layer(\"predictions\")(x_2) \n",
    "model_2=keras.Model(input_2,x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientTape 함수를 이용한 그레이디언트 계산\n",
    "with tf.GradientTape() as tape:\n",
    "    output_1=model_1(x)\n",
    "    tape.watch(output_1) # 마지막 층으로 미분하기 위한 준비\n",
    "    preds=model_2(output_1)\n",
    "    class_id=tf.argmax(preds[0])\n",
    "    output_2=preds[:,class_id]\n",
    "\n",
    "grads=tape.gradient(output_2,output_1) # 그레이디언트 계산\n",
    "pooled_grads=tf.reduce_mean(grads,axis=(0,1,2)) \n",
    "\n",
    "output_1=output_1.numpy()[0]\n",
    "pooled_grads=pooled_grads.numpy()\n",
    "for i in range(pooled_grads.shape[-1]): \n",
    "    output_1[:,:,i]*=pooled_grads[i]\n",
    "heatmap=np.mean(output_1,axis=-1)\n",
    "\n",
    "heatmap=np.maximum(heatmap,0)/np.max(heatmap) # [0,1]로 정규화\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 열지도를 입력 영상에 덧씌움\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m img\u001b[38;5;241m=\u001b[39m\u001b[43mimage\u001b[49m\u001b[38;5;241m.\u001b[39mload_img(image_path) \u001b[38;5;66;03m# 입력 영상을 다시 받아옴\u001b[39;00m\n\u001b[1;32m      4\u001b[0m img\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n\u001b[1;32m      5\u001b[0m heatmap\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8(\u001b[38;5;241m255\u001b[39m\u001b[38;5;241m*\u001b[39mheatmap) \u001b[38;5;66;03m# [0,255]로 변환\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "# 열지도를 입력 영상에 덧씌움\n",
    "img=image.load_img(image_path) # 입력 영상을 다시 받아옴\n",
    "\n",
    "img=image.img_to_array(img)\n",
    "heatmap=np.uint8(255*heatmap) # [0,255]로 변환\n",
    "\n",
    "jet=cm.get_cmap(\"jet\") # [0,255] 열지도를 jet 컬러맵으로 표시함\n",
    "color=jet(np.arange(256))[:,:3]\n",
    "color_heatmap=color[heatmap]\n",
    "\n",
    "color_heatmap=keras.preprocessing.image.array_to_img(color_heatmap)\n",
    "color_heatmap=color_heatmap.resize((img.shape[1],img.shape[0]))\n",
    "color_heatmap=keras.preprocessing.image.img_to_array(color_heatmap)\n",
    "\n",
    "overlay_img=color_heatmap*0.4+img # 덧씌움\n",
    "overlay_img=keras.preprocessing.image.array_to_img(overlay_img)\n",
    "plt.matshow(overlay_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "day16_1_jupyter",
   "language": "python",
   "name": "day16_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
