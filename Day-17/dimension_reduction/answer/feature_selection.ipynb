{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **라이브러리 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 전처리 패키지\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 모델 패키지\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# 모델 평가 패키지\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, root_mean_squared_error\n",
    "\n",
    "# 시각화 패키지\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **차원 축소 - 변수 선택법**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 기본 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005798,
     "end_time": "2020-09-04T09:54:24.417844",
     "exception": false,
     "start_time": "2020-09-04T09:54:24.412046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1-1. 데이터 불러오기 및 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToyotaCorolla.csv\n",
    "- 중고차 판매 데이터 셋\n",
    "- 가격, 연식, 주행 거리, 연료 유형, 엔진 크기, 옵션 정보 등 여러 변수 포함\n",
    "- 목표 변수 : 'Price'(중고차 가격)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"../data/ToyotaCorolla.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-04T09:54:24.431177Z",
     "iopub.status.busy": "2020-09-04T09:54:24.430243Z",
     "iopub.status.idle": "2020-09-04T09:54:25.592319Z",
     "shell.execute_reply": "2020-09-04T09:54:25.591818Z"
    },
    "papermill": {
     "duration": 1.169654,
     "end_time": "2020-09-04T09:54:25.592479",
     "exception": false,
     "start_time": "2020-09-04T09:54:24.422825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1-2. 데이터 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "# 'Price'를 종속 변수로 설정\n",
    "X = data.drop(columns=['Price', 'Id', 'Model'])  # 독립 변수\n",
    "y = data['Price']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=34)\n",
    "\n",
    "# object변수 One-Hot-Encoding\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# bool변수 int변환\n",
    "X_train = X_train.astype({col: 'int' for col in X_train.select_dtypes(include='bool').columns})\n",
    "X_test = X_test.astype({col: 'int' for col in X_test.select_dtypes(include='bool').columns})\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_constant를 통해 상수항 생성\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "# 모델 형성 및 결과 출력\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 전진선택법**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X와 y 정의\n",
    "variables = X_train.columns.tolist()  # 독립 변수들의 리스트 생성\n",
    "y = y_train  # 종속 변수 설정\n",
    "\n",
    "# 선택된 변수들을 저장할 리스트\n",
    "forward_variables = []\n",
    "\n",
    "# 전진 선택법에서 기준이 되는 p-value 설정\n",
    "sl_enter = 0.05  # 변수를 추가할 때의 p-value 기준\n",
    "sl_remove = 0.05  # 변수를 제거할 때의 p-value 기준\n",
    "\n",
    "# 각 스텝별로 선택된 변수들 및 수정된 결정계수(R²) 기록\n",
    "sv_per_step = []  # 각 단계에서 선택된 변수들\n",
    "adj_r_squared_list = []  # 각 단계에서 계산된 수정 결정 계수\n",
    "steps = []  # 단계 기록\n",
    "step = 0  # 현재 단계\n",
    "\n",
    "# 전진 선택법 (Forward Selection) 알고리즘 시작\n",
    "while len(variables) > 0:  # 아직 선택되지 않은 변수가 있는 동안 반복\n",
    "    remainder = list(set(variables) - set(forward_variables))  # 현재 선택되지 않은 변수들\n",
    "    pval = pd.Series(index=remainder)  # 각 변수의 p-value를 저장할 시리즈 생성\n",
    "    \n",
    "    # 각 변수에 대해 모델을 피팅하여 p-value 계산\n",
    "    for col in remainder:\n",
    "        X = X_train[forward_variables + [col]]  # 현재 선택된 변수와 후보 변수를 포함한 독립 변수\n",
    "        X = sm.add_constant(X)  # 상수(constant) 추가 (절편 계산을 위해 필요)\n",
    "        forward_model = sm.OLS(y, X).fit(disp=0)  # OLS(Ordinary Least Squares) 회귀 모델 적합\n",
    "        pval[col] = forward_model.pvalues[col]  # 해당 변수의 p-value 저장\n",
    "    \n",
    "    # p-value가 가장 낮은 변수 선택\n",
    "    min_pval = pval.min()\n",
    "    if min_pval < sl_enter:  # 기준 p-value(sl_enter)보다 작으면 변수 추가\n",
    "        forward_variables.append(pval.idxmin())  # 가장 낮은 p-value의 변수 추가\n",
    "        \n",
    "        # 추가한 변수 중 p-value가 높은 변수를 제거하는 과정\n",
    "        while len(forward_variables) > 0:  # 선택된 변수가 있는 동안 반복\n",
    "            selected_X = X_train[forward_variables]  # 현재 선택된 변수로 독립 변수 생성\n",
    "            selected_X = sm.add_constant(selected_X)  # 상수 추가\n",
    "            selected_pval = sm.OLS(y, selected_X).fit(disp=0).pvalues[1:]  # 각 변수의 p-value 계산\n",
    "            max_pval = selected_pval.max()  # 가장 높은 p-value 선택\n",
    "            if max_pval >= sl_remove:  # 기준 p-value(sl_remove)보다 크면 변수 제거\n",
    "                remove_variable = selected_pval.idxmax()  # 제거할 변수 선택\n",
    "                forward_variables.remove(remove_variable)  # 변수 제거\n",
    "            else:\n",
    "                break  # 기준을 만족하면 제거 중단\n",
    "        \n",
    "        # 단계 업데이트 및 기록\n",
    "        step += 1\n",
    "        steps.append(step)  # 현재 단계 기록\n",
    "        adj_r_squared = sm.OLS(y, sm.add_constant(X_train[forward_variables])).fit(disp=0).rsquared_adj  # 수정된 결정계수 계산\n",
    "        adj_r_squared_list.append(adj_r_squared)  # 수정된 결정계수 기록\n",
    "        sv_per_step.append(forward_variables.copy())  # 선택된 변수 리스트 복사 후 기록\n",
    "    else:\n",
    "        break  # p-value 기준을 만족하는 변수가 없으면 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **step별 선택된 변수와 r 값 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 설정\n",
    "fig = plt.figure(figsize=(10, 10))  # 그래프 크기 설정\n",
    "fig.set_facecolor('white')  # 그래프 배경색 설정\n",
    "\n",
    "# 글꼴 크기 설정\n",
    "font_size = 15\n",
    "\n",
    "# x축 눈금 설정\n",
    "plt.xticks(\n",
    "    steps,  # x축 눈금 위치\n",
    "    [f'step {s}\\n' + '\\n'.join(sv_per_step[i]) for i, s in enumerate(steps)],  # 각 단계의 변수 표시\n",
    "    fontsize=1  # x축 눈금 폰트 크기 (작게 설정)\n",
    ")\n",
    "\n",
    "# 수정된 결정계수(adj_r_squared) 그래프\n",
    "plt.plot(steps, adj_r_squared_list, marker='o')  # 각 단계의 결정계수 값 연결\n",
    "\n",
    "# y축 레이블 설정\n",
    "plt.ylabel('adj_r_squared', fontsize=font_size)\n",
    "\n",
    "# 격자 표시\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전진선택법 적용 모델\n",
    "forward_model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train[forward_variables]))).fit(disp=0)\n",
    "forward_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 후진 소거법**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_regression(X, y,\n",
    "                           initial_list=[], \n",
    "                           threshold_out = 0.05, # 후진선택시 고려할 기준 p-value   \n",
    "                           feature_list = X_train.columns.tolist()\n",
    "                           ):\n",
    "    # 결과 저장용 리스트 초기화\n",
    "    sv_per_step = [] # 각 스텝별로 선택된 변수들\n",
    "    adj_r_squared_list = [] # 각 스텝별 수정된 결정계수\n",
    "    steps = [] # 스텝\n",
    "    step = 0\n",
    "\n",
    "    # 초기 포함된 변수 리스트 설정\n",
    "    included = feature_list\n",
    "\n",
    "    while True:\n",
    "        changed = False  # 변수 제거 여부를 추적하기 위한 플래그\n",
    "\n",
    "        # 현재 포함된 변수들로 모델 피팅\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[feature_list]))).fit(disp=0)\n",
    "        \n",
    "        # p-value 계산\n",
    "        pvalues = model.pvalues.iloc[1:] # 첫 번째 값(상수항)을 제외한 p-value\n",
    "        worst_pval = pvalues.max() # p-value값이 가장 높은 변수 선택\n",
    "\n",
    "        # p-value가 임계값을 초과하는 경우 변수 제거\n",
    "        if worst_pval > threshold_out:\n",
    "            changed = True\n",
    "            worst_feature = pvalues.idxmax() # 제거할 변수 이름\n",
    "            included.remove(worst_feature) # 변수 제거\n",
    "        \n",
    "        # 단계 및 결과 업데이트\n",
    "        step += 1\n",
    "        steps.append(step)        \n",
    "        adj_r_squared = sm.OLS(y, sm.add_constant(pd.DataFrame(X[feature_list]))).fit(disp=0).rsquared_adj\n",
    "        adj_r_squared_list.append(adj_r_squared) # 수정된 결정계수 저장\n",
    "        sv_per_step.append(included.copy()) # 현재 선택된 변수 저장\n",
    "        \n",
    "        # 더 이상 제거할 변수가 없으면 종료\n",
    "        if not changed:\n",
    "            break\n",
    "      \n",
    "    return included, step, steps, adj_r_squared_list, sv_per_step\n",
    "\n",
    "# 함수 실행\n",
    "backward_variables_function, step, steps, adj_r_squared_list, sv_per_step = backward_regression(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step별 선택된 변수와 r 값 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.set_facecolor('white')\n",
    " \n",
    "font_size = 15\n",
    "plt.xticks(steps,[f'step {s}\\n'+'\\n'.join(sv_per_step[i]) for i,s in enumerate(steps)], fontsize=1)\n",
    "plt.plot(steps, adj_r_squared_list, marker='o')\n",
    "    \n",
    "plt.ylabel('adj_r_squared',fontsize=font_size)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후진소거법 적용 모델\n",
    "back_model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train[backward_variables_function]))).fit(disp=0)\n",
    "back_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. stepwise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_feature_selection(X_train, y_train, variables=X_train.columns.tolist() ):\n",
    "    # 종속 변수 설정\n",
    "    y = y_train \n",
    "\n",
    "    # 선택된 변수 리스트 초기화\n",
    "    selected_variables = [] # 선택된 변수들\n",
    "\n",
    "    # stepwise 시 고려할 기준 p-value 설정\n",
    "    sl_enter = 0.05  # 변수를 추가할 기준 p-value\n",
    "    sl_remove = 0.05  # 변수를 제거할 기준 p-value\n",
    "\n",
    "    # 각 단계별 결과 저장용 리스트 초기화\n",
    "    sv_per_step = [] # 각 스텝별로 선택된 변수들\n",
    "    adjusted_r_squared = [] # 각 스텝별 수정된 결정계수\n",
    "    steps = [] # 스텝\n",
    "    step = 0\n",
    "\n",
    "    while len(variables) > 0:\n",
    "        # 선택되지 않은 변수들로 구성된 후보 리스트 생성\n",
    "        remainder = list(set(variables) - set(selected_variables))\n",
    "        pval = pd.Series(index=remainder) # 각 변수의 p-value 저장용 시리즈\n",
    "        \n",
    "        # 각 변수에 대해 모델 피팅 및 p-value 계산\n",
    "        for col in remainder: \n",
    "            X = X_train[selected_variables + [col]]  # 현재 선택된 변수 + 후보 변수\n",
    "            X = sm.add_constant(X)  # 상수항 추가\n",
    "            model = sm.OLS(y, X).fit(disp=0)  # 회귀 모델 피팅\n",
    "            pval[col] = model.pvalues[col]  # 후보 변수의 p-value 저장\n",
    "    \n",
    "        # p-value가 가장 낮은 변수 선택\n",
    "        min_pval = pval.min()\n",
    "        if min_pval < sl_enter:  # 기준 p-value보다 작으면 변수 선택\n",
    "            selected_variables.append(pval.idxmin())\n",
    "            \n",
    "            # 변수 제거 과정\n",
    "            while len(selected_variables) > 0:\n",
    "                selected_X = X_train[selected_variables]  # 선택된 변수로 모델 피팅\n",
    "                selected_X = sm.add_constant(selected_X)  # 상수항 추가\n",
    "                selected_pval = sm.OLS(y, selected_X).fit(disp=0).pvalues[1:]  # 상수항 제외한 p-value 계산\n",
    "                max_pval = selected_pval.max()  # 가장 높은 p-value 선택\n",
    "                if max_pval >= sl_remove:  # 기준 p-value보다 크면 변수 제거\n",
    "                    remove_variable = selected_pval.idxmax()  # 제거할 변수 선택\n",
    "                    selected_variables.remove(remove_variable)  # 변수 제거\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            # 단계별 결과 업데이트\n",
    "            step += 1\n",
    "            steps.append(step)  # 현재 단계 기록\n",
    "            adj_r_squared = sm.OLS(y, sm.add_constant(X_train[selected_variables])).fit(disp=0).rsquared_adj  # 수정된 결정계수 계산\n",
    "            adjusted_r_squared.append(adj_r_squared)  # 수정된 결정계수 저장\n",
    "            sv_per_step.append(selected_variables.copy())  # 선택된 변수 리스트 저장\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 시각화\n",
    "    fig = plt.figure(figsize=(100, 10))  # 그래프 크기 설정\n",
    "    fig.set_facecolor('white')  # 배경색 설정\n",
    "    \n",
    "    font_size = 15\n",
    "    plt.xticks(steps, [f'step {s}\\n' + '\\n'.join(sv_per_step[i]) for i, s in enumerate(steps)], fontsize=12)  # 단계별 선택된 변수 표시\n",
    "    plt.plot(steps, adjusted_r_squared, marker='o')  # 수정된 결정계수 변화 시각화\n",
    "      \n",
    "    plt.ylabel('Adjusted R Squared', fontsize=font_size)  # y축 레이블 설정\n",
    "    plt.grid(True)  # 격자 표시\n",
    "    plt.show()  # 그래프 출력\n",
    "\n",
    "    return selected_variables\n",
    "\n",
    "# 단계적 선택법 실행\n",
    "selected_variables = stepwise_feature_selection(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stepwise 적용 모델\n",
    "stepwise_model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train[selected_variables]))).fit(disp=0)\n",
    "stepwise_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **성능 비교(RMSE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full featrue\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = sqrt(root_mean_squared_error(y_test, y_pred))\n",
    "print(\"full_rmse : \",rmse)\n",
    "\n",
    "#forward featrue\n",
    "y_pred = forward_model.predict(X_test[forward_variables])\n",
    "\n",
    "rmse = sqrt(root_mean_squared_error(y_test, y_pred))\n",
    "print(\"forward_rmse : \",rmse)\n",
    "\n",
    "#backward featrue\n",
    "y_pred = back_model.predict(X_test[backward_variables_function])\n",
    "\n",
    "rmse = sqrt(root_mean_squared_error(y_test, y_pred))\n",
    "print(\"back_rmse : \",rmse)\n",
    "\n",
    "#stepwise featrue\n",
    "y_pred = stepwise_model.predict(X_test[selected_variables])\n",
    "\n",
    "rmse = sqrt(root_mean_squared_error(y_test, y_pred))\n",
    "print(\"stepwise_rmse : \",rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **5. 유전 알고리즘**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCOS_data.csv\n",
    "- 여성 호르몬 장애 환자들에 대한 데이터 셋\n",
    "- 호르몬 이상을 경험한 환자들의 체내 특성 정보 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수 컬럼 확인 및 라벨인코딩 함수\n",
    "def preprocess_data(data):\n",
    "    # 범주형 변수 확인\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_columns:\n",
    "        data[col] = LabelEncoder().fit_transform(data[col])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "data = pd.read_csv(\"../data/PCOS_data.csv\")\n",
    "data = preprocess_data(data) # 라벨 인코딩\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "# 'PCOS (Y/N)'을 종속 변수로 설정\n",
    "X = data.drop(columns=['PCOS (Y/N)', 'Sl. No', 'Patient File No.', 'Unnamed: 44'], errors='ignore')  # 독립 변수\n",
    "y = data['PCOS (Y/N)']\n",
    "\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유전 알고리즘 설정\n",
    "# Fitness 함수 정의 (정확도를 최대화하는 문제)\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유전자의 표현 (특성 선택 여부를 0 또는 1로 표시)\n",
    "toolbox.register(\"attr_bool\", np.random.randint, 2)\n",
    "\n",
    "# 개체 생성 (특성의 수만큼 0 또는 1로 이루어진 리스트)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=X.shape[1])\n",
    "\n",
    "# 개체군 생성\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(individual):\n",
    "    # 선택된 특성만으로 모델 학습 및 평가\n",
    "    selected_features = [index for index, value in enumerate(individual) if value == 1]  # 선택된 특성의 인덱스 추출\n",
    "    if len(selected_features) == 0:  # 특성을 하나도 선택하지 않은 경우 패널티 부여\n",
    "        return 0.0,\n",
    "    \n",
    "    # 선택된 특성으로 학습 데이터와 테스트 데이터 구성\n",
    "    X_train_selected = X_train.iloc[:, selected_features]  # 선택된 특성의 학습 데이터\n",
    "    X_test_selected = X_test.iloc[:, selected_features]  # 선택된 특성의 테스트 데이터\n",
    "\n",
    "    # 모델 학습 및 예측\n",
    "    model = RandomForestClassifier(random_state=42)  # 랜덤 포레스트 모델 초기화\n",
    "    model.fit(X_train_selected, y_train)  # 모델 학습\n",
    "    predictions = model.predict(X_test_selected)  # 테스트 데이터 예측\n",
    "\n",
    "    # 정확도 계산\n",
    "    accuracy = accuracy_score(y_test, predictions)  # 예측 정확도 계산\n",
    "    return accuracy,\n",
    "\n",
    "# 교배, 변이, 선택 연산 정의\n",
    "# GA(유전 알고리즘)에서 사용하는 연산자 등록\n",
    "toolbox.register(\"evaluate\", evaluate)  # 평가 함수 등록\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)  # 두 점 교배 연산 등록\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)  # 비트 플립 변이 연산 등록 (indpb는 변이 확률)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)  # 토너먼트 선택 연산 등록 (tournsize는 토너먼트 크기)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = RandomForestClassifier(random_state=42)\n",
    "initial_model.fit(X_train, y_train)\n",
    "initial_predictions = initial_model.predict(X_test)\n",
    "initial_accuracy = accuracy_score(y_test, initial_predictions)\n",
    "print(f\"Initial accuracy (all features): {initial_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유전 알고리즘으로 변수 선택 수행\n",
    "population = toolbox.population(n=50)  # 초기 개체군 크기\n",
    "ngen = 20  # 세대 수\n",
    "cxpb = 0.5  # 교배 확률\n",
    "mutpb = 0.2  # 변이 확률\n",
    "\n",
    "# 통계 정보 출력 설정\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)  # 개체의 적합도 값에 대한 통계 설정\n",
    "stats.register(\"avg\", np.mean)  # 세대별 평균 적합도 계산\n",
    "stats.register(\"min\", np.min)  # 세대별 최소 적합도 계산\n",
    "stats.register(\"max\", np.max)  # 세대별 최대 적합도 계산\n",
    "\n",
    "# 유전 알고리즘 실행\n",
    "population, logbook = algorithms.eaSimple(\n",
    "    population, toolbox, cxpb, mutpb, ngen, stats=stats, verbose=True  # 알고리즘 실행 및 통계 출력\n",
    ")\n",
    "\n",
    "# 최적의 해 찾기\n",
    "best_individual = tools.selBest(population, k=1)[0]  # 최적의 개체 선택\n",
    "selected_features = [index for index, value in enumerate(best_individual) if value == 1]  # 선택된 특성 인덱스 추출\n",
    "print(f\"Best individual: {best_individual}\")  # 최적의 개체 출력\n",
    "print(f\"Selected features: {selected_features}\")  # 선택된 특성 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 특성을 사용한 모델 정확도 계산\n",
    "if len(selected_features) > 0:\n",
    "    X_train_selected = X_train.iloc[:, selected_features]\n",
    "    X_test_selected = X_test.iloc[:, selected_features]\n",
    "\n",
    "    final_model = RandomForestClassifier(random_state=42)\n",
    "    final_model.fit(X_train_selected, y_train)\n",
    "    final_predictions = final_model.predict(X_test_selected)\n",
    "    final_accuracy = accuracy_score(y_test, final_predictions)\n",
    "    print(f\"Final accuracy (selected features): {final_accuracy:.4f}\")\n",
    "else:\n",
    "    final_accuracy = 0.0\n",
    "    print(\"No features were selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement = final_accuracy - initial_accuracy\n",
    "print(f\"Accuracy improvement: {improvement:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "day17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "papermill": {
   "duration": 17.139704,
   "end_time": "2020-09-04T09:54:36.978104",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-04T09:54:19.838400",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
