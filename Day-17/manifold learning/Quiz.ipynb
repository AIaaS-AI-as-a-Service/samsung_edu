{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #ffd33d\">**문제 1. 매니폴드 학습에 대한 설명으로 옳지 않은 것은?**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp; &#9312; 고차원 데이터를 데이터 공간에 뿌려 샘플들을 잘 아우르는 subspace가 있을 것이라 가정에서 학습을 진행하는 방법이다.\n",
    "\n",
    "&emsp; &#9313; 고차원 데이터를 잘 표현하고 이로 인해 데이터의 중요한 특징을 발견할 수 있다.\n",
    "\n",
    "&emsp; &#9314; 매니폴드 학습을 하면 차원의 저주 문제를 해결 할 수 있다.\n",
    "\n",
    "&emsp; &#9315; 매니폴드 학습은 데이터를 압축하는데 효과가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #ffd33d\">**문제 2. t-SNE에 대한 설명으로 틀린 것은 ?**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp; &#9312; 매니폴드 학습의 하나의 방법으로 데이터의 시각화에 효과적이다.\n",
    "\n",
    "&emsp; &#9313; 고차원 공간에서 유클리드 거리를 포인트들 간 유사성을 표현하는 조건부 확률로 변환하는 방법이다.\n",
    "\n",
    "&emsp; &#9314; 차원 축소의 속도가 빠르다.\n",
    " \n",
    "&emsp; &#9315; 저차원으로 임베딩 할 때, 정보손실이 발생할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #ffd33d\">**문제 3. LLE(Local Linear Embedding)와 ISOMAP에 대한 설명으로 틀린 것은 ?**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp; &#9312; 고차원의 공간에서 인접해 있는 데이터들 사이의 선형적 구조를 보존하면서 저차원으로 임베딩하는 방법론이다.\n",
    "\n",
    "&emsp; &#9313; LLE는 투영에 의존하는 매니폴드 학습 방법이다. \n",
    "\n",
    "&emsp; &#9314; ISOMAP은 각 데이터 포인트를 가장 가까운 이웃과 연결하는 그래프를 만들고 두 노드 사이의 최단 경로 geodestic distance를 유지하며 차원 축소한다.\n",
    " \n",
    "&emsp; &#9315; ISOMAP은 PCA와 MDS의 주요 알고리즘 특징을 결합한 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #ffd33d\">**문제 4. Undersampling의 특징 중 틀린 것은 ?**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp; &#9312; 데이터 손실이 적다.\n",
    "\n",
    "&emsp; &#9313; 계산 시간이 감소한다.\n",
    "\n",
    "&emsp; &#9314; 데이터 왜곡이 발생한다.\n",
    " \n",
    "&emsp; &#9315; 대표적인 기법으로 random sampling, Tomek Links가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #ffd33d\">**문제 5. Oversampling 기법들의 설명 중 옳은 것은?**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp; &#9312; Oversampling 기법 중 Resampling은 적은 수의 관측치를 복제해 계속해서 새로운 정보를 얻을 수 있다.\n",
    "\n",
    "&emsp; &#9313; Synthetic Minority Oversampling Technique(SMOTE) 기법은 선택된 두 관측치를 기반으로 가상의 관측치를 생성하는 기법이다.\n",
    "\n",
    "&emsp; &#9314; Borderline-SMOTE 기법을 사용할 때에는 Borderline에 먼 관측치 일수록 중요한 관측치이다.\n",
    " \n",
    "&emsp; &#9315; ADASYN 기법은 Borderline 인근 샘플링에 좀 더 집중하기 위한 방법으로 각각의 다수 클래스 관측치 주변에 얼만큼 많은 소수 클래스 관측치들이 있는가를 정량화 한 지표를 사용한다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
