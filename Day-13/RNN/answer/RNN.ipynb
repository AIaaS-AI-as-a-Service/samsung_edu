{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **라이브러리 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 전처리 패키지\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 모델 패키지\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# 모델 평가 패키지\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP9Qr2-36gAf"
   },
   "source": [
    "# **1. 순환 신경망(Recurrent Neural Network, RNN)**\n",
    "\n",
    "- 루프(loop)를 가진 신경망의 한 종류\n",
    "\n",
    "- 시퀀스의 원소를 순회하면서 지금까지 처리한 정보를 상태(state)에 저장\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/627/1*go8PHsPNbbV6qRiwpUQ5BQ.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0CNAzN_deXE"
   },
   "source": [
    "## **1.1. RNN 모델 실습 : IMDB 데이터 with RNN(이진분류)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **IMDB 데이터 셋** ###\n",
    "- 영화 리뷰 데이터\n",
    "- 영화 리뷰, 긍정/부정 레이블로 구성(이진 분류)\n",
    "- 텍스트 분석 작업에서 주로 활용\n",
    "- 50000개의 리뷰 데이터 (Train 25000, Test 25000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1SbNYRdmVTY"
   },
   "source": [
    "### **데이터 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pad sequences**\n",
    "- 가변 길이 시퀀스를 동일한 길이로 맞추기 위해 패딩을 추가하는 함수\n",
    "- 입력 시퀀스를 리스트로 받아 가장 긴 시퀀스에 맞춰 나머지 시퀀스 뒤에 패딩 값을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({\"sentiment\": {\"positive\": 1, \"negative\": 0}}, inplace=True)  # 'sentiment' 열의 값을 'positive' -> 1, 'negative' -> 0으로 변환\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)  # 데이터를 80:20 비율로 훈련/테스트 세트로 분할\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)  # 최대 5000개의 단어를 사용해 텍스트를 토큰화하는 Tokenizer 생성\n",
    "tokenizer.fit_on_texts(train_data[\"review\"])  # 훈련 데이터의 'review' 텍스트로 Tokenizer에 단어 사전 생성\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"review\"]), maxlen=200)  # 훈련 데이터를 시퀀스로 변환하고, 길이를 200으로 패딩\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"review\"]), maxlen=200)    # 테스트 데이터를 시퀀스로 변환하고, 길이를 200으로 패딩\n",
    "\n",
    "Y_train = train_data[\"sentiment\"]  # 훈련 데이터의 'sentiment' 열을 레이블로 설정\n",
    "Y_test = test_data[\"sentiment\"]    # 테스트 데이터의 'sentiment' 열을 레이블로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 구성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 128))\n",
    "model.add(SimpleRNN(128, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    epochs = 10,\n",
    "                    batch_size = 128,\n",
    "                    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afIyKdLsmj6N"
   },
   "source": [
    "### **학습과정 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sendhEujeu8S"
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']  # 훈련 데이터의 손실 값 추적\n",
    "val_loss = history.history['val_loss']  # 검증 데이터의 손실 값 추적\n",
    "acc = history.history['acc']  # 훈련 데이터의 정확도 추적\n",
    "val_acc = history.history['val_acc']  # 검증 데이터의 정확도 추적\n",
    "\n",
    "epochs = range(1, len(loss)+1)  # 에포크 범위 생성\n",
    "\n",
    "# 손실 값 시각화\n",
    "plt.plot(epochs, loss, 'b--', label='training loss')  # 훈련 손실 그래프 (파란 점선)\n",
    "plt.plot(epochs, val_loss, 'r:', label='validation loss')  # 검증 손실 그래프 (빨간 점선)\n",
    "plt.grid()  # 격자 표시\n",
    "plt.legend()  # 범례 표시\n",
    "\n",
    "# 새로운 Figure 생성 후 정확도 시각화\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'b--', label='training accuracy')  # 훈련 정확도 그래프 (파란 점선)\n",
    "plt.plot(epochs, val_acc, 'r:', label='validation accuracy')  # 검증 정확도 그래프 (빨간 점선)\n",
    "plt.grid()  # 격자 표시\n",
    "plt.legend()  # 범례 표시\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rjMFpiBe4Fa"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2. RNN 모델 실습 : Reuters 데이터 with RNN(다중분류)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reuters**\n",
    "\n",
    "- IMDB와 유사한 텍스트 데이터셋\n",
    "- 1986년 로이터에서 공개한 짧은 뉴스 기사 및 토픽의 집합\n",
    "- 46개의 상호 배타적인 토픽으로 이루어진 데이터셋(다중 분류)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuters.npz 파일에서 데이터 로드\n",
    "data = np.load('./data/reuters.npz', allow_pickle=True)\n",
    "\n",
    "# 데이터로부터 x, y변수 추출\n",
    "x = data['x']\n",
    "y = data['y']\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 차원 확인\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 동일한 길이로 패딩 처리\n",
    "x_train = pad_sequences(x_train, maxlen=100, padding='post')\n",
    "x_test = pad_sequences(x_test, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원 핫 인코딩\n",
    "y_train = to_categorical(y_train, num_classes=46)  # 46은 클래스 수\n",
    "y_test = to_categorical(y_test, num_classes=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 구성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(10000, 500))\n",
    "model2.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model2.add(Dense(46, activation='softmax'))\n",
    "\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(x_train, y_train,\n",
    "                    batch_size = 128, epochs = 10,\n",
    "                    validation_split=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **학습과정 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "acc = history2.history['acc']\n",
    "val_acc = history2.history['val_acc']\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'b--', label = 'training loss')\n",
    "plt.plot(epochs, val_loss, 'r:', label = 'validation loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'b--', label = 'training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r:', label = 'validation accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTmZ_XiZguM5"
   },
   "source": [
    "#### **SimpleRNN의 한계점**\n",
    "\n",
    "- SimpleRNN은 실전에 사용하기엔 너무 단순\n",
    "\n",
    "- SimpleRNN은 이론적으로 시간 $t$ 에서 이전의 모든 타임스텝의 정보를 유지할 수 있지만, 실제로는 긴 시간에 걸친 의존성은 학습할 수 없음\n",
    "\n",
    "- 그래디언트 소실 문제(vanishing gradient problem)\n",
    "  - 이를 방지하기 위해 **LSTM** 등장\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZXJIdDai7sV"
   },
   "source": [
    "# **2. LSTM(Long Short-Term Memory)**\n",
    "- 장단기 메모리 알고리즘\n",
    "\n",
    "- 나중을 위해 정보를 저장함으로써 오래된 시그널이 점차 소실되는 것을 막아줌\n",
    "\n",
    "  <img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\">\n",
    "\n",
    "  <sub>출처: https://colah.github.io/posts/2015-08-Understanding-LSTMs/</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1. LSTM 모델 실습 : IMDB 데이터(이진분류)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({\"sentiment\": {\"positive\": 1, \"negative\": 0}}, inplace=True)  # 'sentiment' 열의 값을 'positive' -> 1, 'negative' -> 0으로 변환\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)  # 데이터를 80:20 비율로 훈련/테스트 세트로 분할\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)  # 최대 5000개의 단어를 사용해 텍스트를 토큰화하는 Tokenizer 생성\n",
    "tokenizer.fit_on_texts(train_data[\"review\"])  # 훈련 데이터의 'review' 텍스트로 Tokenizer에 단어 사전 생성\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"review\"]), maxlen=200)  # 훈련 데이터를 시퀀스로 변환하고, 길이를 200으로 패딩\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"review\"]), maxlen=200)    # 테스트 데이터를 시퀀스로 변환하고, 길이를 200으로 패딩\n",
    "\n",
    "Y_train = train_data[\"sentiment\"]  # 훈련 데이터의 'sentiment' 열을 레이블로 설정\n",
    "Y_test = test_data[\"sentiment\"]    # 테스트 데이터의 'sentiment' 열을 레이블로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 구성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(5000, 128))\n",
    "model3.add(LSTM(128, dropout=0.3, recurrent_dropout=0.3))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(optimizer='rmsprop',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model3.fit(X_train, Y_train,\n",
    "                    epochs = 10,\n",
    "                    batch_size =128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history3.history['loss']\n",
    "val_loss = history3.history['val_loss']\n",
    "acc = history3.history['acc']\n",
    "val_acc = history3.history['val_acc']\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'b--', label = 'training loss')\n",
    "plt.plot(epochs, val_loss, 'r:', label = 'validation loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'b--', label = 'training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r:', label = 'validation accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2. LSTM 모델 실습 : Reuters 데이터 (다중분류)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONPaMDFEsftq"
   },
   "source": [
    "### 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuters.npz 파일에서 데이터 로드\n",
    "data = np.load('./data/reuters.npz', allow_pickle=True)\n",
    "\n",
    "# 데이터로부터 x, y변수 추출\n",
    "x = data['x']\n",
    "y = data['y']\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 차원 확인\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 전처리 및 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 동일한 길이로 패딩 처리\n",
    "x_train = pad_sequences(x_train, maxlen=100, padding='post')\n",
    "x_test = pad_sequences(x_test, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원 핫 인코딩\n",
    "y_train = to_categorical(y_train, num_classes=46)  # 46은 클래스 수\n",
    "y_test = to_categorical(y_test, num_classes=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 구성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(10000, 500))\n",
    "model2.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model2.add(Dense(46, activation='softmax'))\n",
    "\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(x_train, y_train,\n",
    "                    batch_size = 128, epochs = 10,\n",
    "                    validation_split=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **학습과정 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "acc = history2.history['acc']\n",
    "val_acc = history2.history['val_acc']\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'b--', label = 'training loss')\n",
    "plt.plot(epochs, val_loss, 'r:', label = 'validation loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'b--', label = 'training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r:', label = 'validation accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVxVV-kmsT6D"
   },
   "outputs": [],
   "source": [
    "model2.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. 시계열 데이터 셋을 활용한 RNN / LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Airline-passengers dataset**\n",
    "- 1949년 1월 ~ 1960년 12월(144개월) 사이의 월간 비행기 이용객 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1. 시계열 데이터 셋을 활용한 RNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 로드 및 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/airline-passengers.csv', usecols=[1], engine='python')\n",
    "plt.plot(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 로드 및 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수생성기 시드 설정\n",
    "np.random.seed(2020)\n",
    "\n",
    "# 데이터 불러오기\n",
    "dataset = dataset.values\n",
    "dataset = dataset.astype('float32')\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# 데이터 분리\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배열의 값을 데이터셋 행렬로 변환\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=t 와 Y=t+1 로 변환\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# 배열을 [samples, time steps, features] 형태로 변환\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 구성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units = 32, activation='tanh', input_shape=(1,look_back)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY,\n",
    "          epochs=100, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 예측**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 수행\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# 예측 반전\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# MSE 산출\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **예측 결과 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 예측 값 plot을 위한 shift 수행\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# 테스트 예측 값 plot을 위한 shift 수행\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2. 실습 : 시계열 데이터 셋을 활용한 LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 로드 및 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/airline-passengers.csv', usecols=[1], engine='python')\n",
    "plt.plot(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 로드 및 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수생성기 시드 설정\n",
    "np.random.seed(2020)\n",
    "\n",
    "# 데이터 불러오기\n",
    "dataset = dataset.values\n",
    "dataset = dataset.astype('float32')\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# 데이터 분리\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배열의 값을 데이터셋 행렬로 변환하는 함수\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=t 와 Y=t+1 로 변환\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# 배열을 [samples, time steps, features] 형태로 변환\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 구성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units = 32, activation='tanh', input_shape=(1,look_back)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY,\n",
    "          epochs=100, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 예측**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 수행\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# 예측 반전\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# MSE 산출\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **예측 결과 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 예측 값 plot을 위한 shift 수행\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# 테스트 예측 값 plot을 위한 shift 수행\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "day131",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
